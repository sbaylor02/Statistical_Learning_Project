splitIndex <- createDataPartition(dat_v$Absent_time, p = .50,
list = FALSE,
times = 1)
trainSplit <- dat_v[ splitIndex,]
testSplit <- dat_v[-splitIndex,]
trainSplit$Absent_time <- as.factor(trainSplit$Absent_time)
trainSplit <- SMOTE(Absent_time ~ ., trainSplit, perc.over = 100, perc.under=200)
prop.table(table(trainSplit$Absent_time))
#######
#labels to make inserted code work
validate_id <- c(1:nrow(testSplit))
training_id <- c(1:nrow(trainSplit))
#rename to work with rest of code
dat_v_train <- trainSplit
dat_v_val <- testSplit
AB_class_train <- trainSplit$Absent_time
AB_class_val <- testSplit$Absent_time
#Confirms data comes out as expected
table(AB_class_train)
#Study significance of the variables
rf <- randomForest(Absent_time ~.,
data=dat_v_train,
mtry=6,
ntree=50,
na.action=na.roughfix)
impfact <- importance(rf)
impfact <- as.list(impfact)
names(impfact) <- colnames(dat_v[,-20])
impfact2 <- unlist(impfact)
most_sig_stats <- names(sort(desc(impfact2)))
#Re ordering variables by significance:
dat_v_train_ord <- dat_v_train[ c(most_sig_stats)]
str(dat_v_train_ord)
dat_v_val_ord <- dat_v_val[, names(dat_v_train_ord)]
str(dat_v_val_ord)
#######################
#######################
#Monte Carlo Validation:
size <- nrow(dat_v_train)
sub <- (2/3) * nrow(dat_v_train)
training_family_L <- lapply(1:500, function(j) {
perm <- sample(1:size, size = size, replace = F)
shuffle <- training_id[perm]
trn <- shuffle[1:sub]
trn
})
validation_family_L <- lapply(training_family_L,
function(x) setdiff(training_id, x))
#Finding an optimal set of variables and optimal k
N <- seq(from = 2, to = 19, by = 1)
sqrt(length(training_family_L[[1]]))
K <- seq(from = 1, to = 19, by = 2)
times <- 500 * length(N) * length(K)
#Execution of the test with loops
paramter_errors_df <- data.frame(mc_index = as.integer(rep(NA, times = times)),
var_num = as.integer(rep(NA, times = times)),
k = as.integer(rep(NA, times = times)),
error = as.numeric(rep(NA, times = times)))
param_df1 <- merge(data.frame(mc_index = 1:500), data.frame(var_num = N))
param_df <- merge(param_df1, data.frame(k = K))
N <- seq(from = 2, to = 19, by = 1)
sqrt(length(training_family_L[[1]]))
K <- seq(from = 1, to = 19, by = 2)
times <- 500 * length(N) * length(K)
core_knn_sen <- function(j, n, k) {
knn_predict <- knn(train = dat_v_train_ord[training_family_L[[j]], 1:n],
test = dat_v_train_ord[validation_family_L[[j]], 1:n],
cl = AB_class_train[training_family_L[[j]]],
k = k)
tbl <- table(knn_predict, AB_class_train[validation_family_L[[j]]])
sen <- (tbl[2, 2] )/(tbl[1, 2] + tbl[2, 2])
sen
}
param_df1_2 <- merge(data.frame(mc_index = 1:500), data.frame(var_num = N))
param_df_2 <- merge(param_df1_2, data.frame(k = K))
knn_err_est_df_2 <- ddply(param_df_2[1:times, ], .(mc_index, var_num, k), function(df) {
sen <- core_knn_sen(df$mc_index[1], df$var_num[1], df$k[1])
sen
})
set.seed(1876)
dat <- read_excel("Absenteeism_at_work.xls")
col <- c("ID", "Reason for absence", "Month of absence", "Day of the week", "Seasons", "Disciplinary failure", "Education", "Social drinker",   "Social smoker")
dat[col] <- lapply(dat[col], as.factor)
colnames(dat) <- c("ID", "Reason", "Month", "Day", "Seasons", "Transportation_expense", "Distance", "Service_time", "Age", "Work_load", "Hit_target", "Disciplinary_failure", "Education", "Children", "Social_drinker", "Social_smoker", "Pet", "Weight", "Height", "BMI", "Absent_time")
nums <- unlist(lapply(dat, is.numeric))
dat.num <- dat[ , nums]
#change variable represent missed time one day or greater
dat <- dat %>% mutate(Absent_time= ifelse(dat$Absent_time <=8,0,1))
str(dat)
dat$Absent_time <- as.factor(dat$Absent_time)
#Transforming to Data Frame
dat <- as.data.frame(dat)
str(dat)
###Optimizing the KNN
#For the tunning of the KNN model, we are going to create another traning/test data sets.
#scaling the data:
dat_v <- dat #we are going to use dat_v for the manipulation
scale <- sapply(dat_v, is.numeric)
dat_v[scale] <- lapply(dat_v[scale],scale)
head(dat_v)
#predicting class:
AB_class <- dat_v[, 21]
names(AB_class) <- c(1:nrow(dat_v))
dat_v$ID <- c(1:nrow(dat_v))
dat_v <- dat_v[1:737,]
nrow(dat_v)
rand_permute <- sample(x = nrow(dat_v), size = nrow(dat_v))
all_id_random <- dat_v[rand_permute, "ID"]
dat_v <- dat_v[,-1] #remove ID
#######
splitIndex <- createDataPartition(dat_v$Absent_time, p = .50,
list = FALSE,
times = 1)
trainSplit <- dat_v[ splitIndex,]
testSplit <- dat_v[-splitIndex,]
trainSplit$Absent_time <- as.factor(trainSplit$Absent_time)
trainSplit <- SMOTE(Absent_time ~ ., trainSplit, perc.over = 100, perc.under=200)
prop.table(table(trainSplit$Absent_time))
#######
#labels to make inserted code work
validate_id <- c(1:nrow(testSplit))
training_id <- c(1:nrow(trainSplit))
#rename to work with rest of code
dat_v_train <- trainSplit
dat_v_val <- testSplit
AB_class_train <- trainSplit$Absent_time
AB_class_val <- testSplit$Absent_time
#Confirms data comes out as expected
table(AB_class_train)
#Study significance of the variables
rf <- randomForest(Absent_time ~.,
data=dat_v_train,
mtry=6,
ntree=50,
na.action=na.roughfix)
impfact <- importance(rf)
impfact <- as.list(impfact)
names(impfact) <- colnames(dat_v[,-20])
impfact2 <- unlist(impfact)
most_sig_stats <- names(sort(desc(impfact2)))
#Re ordering variables by significance:
dat_v_train_ord <- dat_v_train[ c(most_sig_stats)]
str(dat_v_train_ord)
dat_v_val_ord <- dat_v_val[, names(dat_v_train_ord)]
str(dat_v_val_ord)
#######################
#######################
#Monte Carlo Validation:
size <- nrow(dat_v_train)
sub <- (2/3) * nrow(dat_v_train)
training_family_L <- lapply(1:500, function(j) {
perm <- sample(1:size, size = size, replace = F)
shuffle <- training_id[perm]
trn <- shuffle[1:sub]
trn
})
validation_family_L <- lapply(training_family_L,
function(x) setdiff(training_id, x))
#Finding an optimal set of variables and optimal k
N <- seq(from = 2, to = 19, by = 1)
sqrt(length(training_family_L[[1]]))
K <- seq(from = 1, to = 19, by = 2)
times <- 500 * length(N) * length(K)
#Execution of the test with loops
paramter_errors_df <- data.frame(mc_index = as.integer(rep(NA, times = times)),
var_num = as.integer(rep(NA, times = times)),
k = as.integer(rep(NA, times = times)),
error = as.numeric(rep(NA, times = times)))
param_df1 <- merge(data.frame(mc_index = 1:500), data.frame(var_num = N))
param_df <- merge(param_df1, data.frame(k = K))
N <- seq(from = 2, to = 19, by = 1)
sqrt(length(training_family_L[[1]]))
K <- seq(from = 1, to = 19, by = 2)
times <- 500 * length(N) * length(K)
core_knn_sen <- function(j, n, k) {
knn_predict <- knn(train = dat_v_train_ord[training_family_L[[j]], 1:n],
test = dat_v_train_ord[validation_family_L[[j]], 1:n],
cl = AB_class_train[training_family_L[[j]]],
k = k)
tbl <- table(knn_predict, AB_class_train[validation_family_L[[j]]])
sen <- (tbl[2, 2] )/(tbl[1, 2] + tbl[2, 2])
sen
}
param_df1_2 <- merge(data.frame(mc_index = 1:500), data.frame(var_num = N))
param_df_2 <- merge(param_df1_2, data.frame(k = K))
knn_err_est_df_2 <- ddply(param_df_2[1:times, ], .(mc_index, var_num, k), function(df) {
sen <- core_knn_sen(df$mc_index[1], df$var_num[1], df$k[1])
sen
})
head(knn_err_est_df_2)
names(knn_err_est_df_2)[4] <- "Sensitivity"
mean_sens_df2 <- ddply(knn_err_est_df_2, .(var_num, k), function(df) mean(df$Sensitivity))
names(mean_sens_df2)[3] <- "mean_sensitivity"
ggplot(data = mean_sens_df2, aes(x = var_num, y = k, color = mean_sensitivity)) + geom_point(size = 5) +
theme_bw()
mean_sens_df2[which.max(mean_sens_df2$mean_sensitivity), ]
order <- mean_sens_df2 %>% arrange(desc(mean_sensitivity))
save(mean_sens_df2, file='mean_sens_df2.RData')
save(order, file='order.RData')
load( file='mean_sens_df2.RData')
load( file='order.RData')
ggplot(data = mean_sens_df2, aes(x = var_num, y = k, color = mean_sensitivity)) + geom_point(size = 5) +
theme_bw()
order
save(mean_sens_df2, file='mean_sens_df2.RData')
save(order, file='order.RData')
load( file='mean_sens_df2.RData')
load( file='order.RData')
R <- 100 # replications
# create the matrix to store values 1 row per model
err_matrix_opt <- matrix(0, ncol=5, nrow=R)
sensitivity_matrix_opt <- matrix(0, ncol=5, nrow=R)
fmeasure_matrix_opt <- matrix(0, ncol=5, nrow=R)
gmean_matrix_opt <- matrix(0, ncol=5, nrow=R)
# these are optional but I like to see how the model did each run so I can check other output
KNNcm <- matrix(0, ncol=4, nrow=R)
KNNcm2 <- matrix(0, ncol=4, nrow=R)
KNNcm3 <- matrix(0, ncol=4, nrow=R)
KNNcm4 <- matrix(0, ncol=4, nrow=R)
KNNcm5 <- matrix(0, ncol=4, nrow=R)
set.seed(1876)
for (r in 1:R){
# subsetting data to training and testing data
splitIndex <- createDataPartition(dat_v$Absent_time, p = .50,
list = FALSE,
times = 1)
trainSplit <- dat_v[ splitIndex,]
testSplit <- dat_v[-splitIndex,]
trainSplit$Absent_time <- as.factor(trainSplit$Absent_time)
trainSplit <- SMOTE(Absent_time ~ ., trainSplit, perc.over = 100, perc.under=200)
################################################################ knn
#Running the classifier
#option 1
knn <- knn(trainSplit[,1:order[1,1]],
test = testSplit[,1:order[1,1]],
cl=trainSplit[,20], k=order[1,2])
#predict doesn't work with KNN for factors
knntable <- table(knn, testSplit[,20])
cm_KNN <-  confusionMatrix(data = knntable, reference = testSplit[,20], positive = "1")
KNNcm [[r,1]] <-  cm_KNN$table[1,1]
KNNcm [[r,2]] <-  cm_KNN$table[1,2]
KNNcm [[r,3]] <-  cm_KNN$table[2,1]
KNNcm [[r,4]] <-  cm_KNN$table[2,2]
err_matrix_opt [[r,1]] <-  (cm_KNN$table[1,2]+cm_KNN$table[2,1])/nrow(testSplit)
# store the errors
sensitivity_matrix_opt[[r, 1]] <- cm_KNN$byClass[1]
fmeasure_matrix_opt [[r, 1]] <- cm_KNN$byClass[7]
gmean_matrix_opt [[r, 1]] <- sqrt(cm_KNN$byClass[1]* cm_KNN$byClass[2])
######################
#option 2
knn <- knn(trainSplit[,1:order[2,1]],
test = testSplit[,1:order[2,1]],
cl=trainSplit[,20], k=order[2,2])
#predict doesn't work with KNN for factors
knntable2 <- table(knn, testSplit[,20])
cm_KNN2 <-  confusionMatrix(data = knntable2, reference = testSplit[,20], positive = "1")
KNNcm2 [[r,1]] <-  cm_KNN2$table[1,1]
KNNcm2 [[r,2]] <-  cm_KNN2$table[1,2]
KNNcm2 [[r,3]] <-  cm_KNN2$table[2,1]
KNNcm2 [[r,4]] <-  cm_KNN2$table[2,2]
err_matrix_opt [[r,2]] <-  (cm_KNN2$table[1,2]+cm_KNN2$table[2,1])/nrow(testSplit)
sensitivity_matrix_opt[[r, 2]] <- cm_KNN2$byClass[1]
fmeasure_matrix_opt [[r, 2]] <- cm_KNN2$byClass[7]
gmean_matrix_opt [[r, 2]] <- sqrt(cm_KNN2$byClass[1]* cm_KNN2$byClass[2])
##########
#option 3
knn <- knn(trainSplit[,1:order[3,1]],
test = testSplit[,1:order[3,1]],
cl=trainSplit[,20], k=order[3,2])
#predict doesn't work with KNN for factors
knntable <- table(knn, testSplit[,20])
cm_KNN3 <-  confusionMatrix(data = knntable, reference = testSplit[,20], positive = "1")
KNNcm3 [[r,1]] <-  cm_KNN3$table[1,1]
KNNcm3 [[r,2]] <-  cm_KNN3$table[1,2]
KNNcm3 [[r,3]] <-  cm_KNN3$table[2,1]
KNNcm3 [[r,4]] <-  cm_KNN3$table[2,2]
err_matrix_opt [[r,3]] <-  (cm_KNN3$table[1,2]+cm_KNN3$table[2,1])/nrow(testSplit)
sensitivity_matrix_opt[[r, 3]] <- cm_KNN3$byClass[1]
fmeasure_matrix_opt [[r, 3]] <- cm_KNN3$byClass[7]
gmean_matrix_opt [[r, 3]] <- sqrt(cm_KNN3$byClass[1]* cm_KNN3$byClass[2])
################
#option 4
knn <- knn(trainSplit[,1:order[4,1]],
test = testSplit[,1:order[4,1]],
cl=trainSplit[,20], k=order[4,2])
#predict doesn't work with KNN for factors
knntable4 <- table(knn, testSplit[,20])
cm_KNN4 <-  confusionMatrix(data = knntable4, reference = testSplit[,20], positive = "1")
KNNcm4 [[r,1]] <-  cm_KNN4$table[1,1]
KNNcm4 [[r,2]] <-  cm_KNN4$table[1,2]
KNNcm4 [[r,3]] <-  cm_KNN4$table[2,1]
KNNcm4 [[r,4]] <-  cm_KNN4$table[2,2]
err_matrix_opt [[r,4]] <-  (cm_KNN4$table[1,2]+cm_KNN4$table[2,1])/nrow(testSplit)
# store the errors
sensitivity_matrix_opt[[r, 4]] <- cm_KNN4$byClass[1]
fmeasure_matrix_opt [[r, 4]] <- cm_KNN4$byClass[7]
gmean_matrix_opt [[r, 4]] <- sqrt(cm_KNN4$byClass[1]* cm_KNN4$byClass[2])
#####################
#option 5
knn <- knn(trainSplit[,1:order[5,1]],
test = testSplit[,1:order[5,1]],
cl=trainSplit[,20], k=order[5,2])
knntable5 <- table(knn, testSplit[,20])
cm_KNN5 <-  confusionMatrix(data = knntable5, reference = testSplit[,20], positive = "1")
KNNcm5 [[r,1]] <-  cm_KNN5$table[1,1]
KNNcm5 [[r,2]] <-  cm_KNN5$table[1,2]
KNNcm5 [[r,3]] <-  cm_KNN5$table[2,1]
KNNcm5 [[r,4]] <-  cm_KNN5$table[2,2]
err_matrix_opt [[r,5]] <-  (cm_KNN5$table[1,2]+cm_KNN5$table[2,1])/nrow( testSplit)
# store the errors
sensitivity_matrix_opt[[r, 5]] <- cm_KNN5$byClass[1]
fmeasure_matrix_opt [[r, 5]] <- cm_KNN5$byClass[7]
gmean_matrix_opt [[r, 5]] <- sqrt(cm_KNN5$byClass[1]* cm_KNN5$byClass[2])
cat("Finished Rep",r, "\n")
}
colnames(sensitivity_matrix_opt)<- c("mod1","mod2","mod3","mod4","mod5")
graph_sens <- melt(sensitivity_matrix_opt)
ggplot(graph_sens,aes(x=Var2, y=value) )+ geom_boxplot()
colnames(err_matrix_opt)<- c("mod1","mod2","mod3","mod4","mod5")
graph_err <- melt(err_matrix_opt)
ggplot(graph_err,aes(x=Var2, y=value) )+ geom_boxplot()
colnames(fmeasure_matrix_opt)<- c("mod1","mod2","mod3","mod4","mod5")
graph_fmeasure <- melt(fmeasure_matrix_opt)
ggplot(graph_fmeasure,aes(x=Var2, y=value) )+ geom_boxplot()
colnames(gmean_matrix_opt)<- c("mod1","mod2","mod3","mod4","mod5")
graph_gmean <- melt(gmean_matrix_opt)
ggplot(graph_gmean,aes(x=Var2, y=value) )+ geom_boxplot()
ggplot(graph_sens,aes(x=Var2, y=value) )+ geom_boxplot()+ labs(y="Sensitivity", title="Sensitivity Comparison of Models")
ggplot(graph_sens,aes(x=Var2, y=value) )+ geom_boxplot()+ labs(y="Sensitivity", title="Sensitivity Comparison of Optimized Models") + theme_minimal()
ggplot(graph_err,aes(x=Var2, y=value) )+ geom_boxplot()
#bind old and new model
comp_matrix_sens2 <- cbind(sensitivity_matrix_opt[,4], sensitivity_matrix[,1])
colnames(comp_matrix_sens2)<- c("Optimized","Original")
graph_comparison <- melt(comp_matrix_sens2)
ggplot(graph_comparison,aes(x=Var2, y=value) )+ geom_boxplot() +labs(x= "Model", y= "Sensitivity") +
theme_minimal()
set.seed(1876)
splitIndex <- createDataPartition(dat_v$Absent_time, p = .50,
list = FALSE,
times = 1)
trainSplit <- dat_v[ splitIndex,]
testSplit <- dat_v[-splitIndex,]
trainSplit$Absent_time <- as.factor(trainSplit$Absent_time)
trainSplit <- SMOTE(Absent_time ~ ., trainSplit, perc.over = 100, perc.under=200)
knn <- knn(trainSplit[,1:order[4,1]],
test = testSplit[,1:order[4,1]],
cl=trainSplit[,20], k=order[4,2])
knntable4 <- table(knn, testSplit[,20])
cm_KNN4 <-  confusionMatrix(data = knntable4, reference = testSplit[,20], positive = "1")
cm_KNN4
set.seed(1876)
dat1 <- dat[-1]
#scale
scale <- sapply(dat1, is.numeric)
dat1[scale] <- lapply(dat1[scale],scale)
p <- .6 # proportion of data for training
w <- sample(1:nrow(dat1), nrow(dat1)*p, replace=F)
data_train <-dat1[w,]
data_test <- dat1[-w,]
#Running the classifier
knn <- knn(data_train[-20],
test = testSplit[-20],
cl=data_train$Absent_time, k=2)
knntable <- table(knn, testSplit$Absent_time)
#generate confusion matrix
cm_KNN <-  confusionMatrix(data = knntable, reference = testSplit[,-20], positive = "1")
cm_KNN
set.seed(1876)
dat1 <- dat[-1]
#scale
scale <- sapply(dat1, is.numeric)
dat1[scale] <- lapply(dat1[scale],scale)
p <- .6 # proportion of data for training
w <- sample(1:nrow(dat1), nrow(dat1)*p, replace=F)
data_train <-dat1[w,]
data_test <- dat1[-w,]
#Running the classifier
knn <- knn(data_train[-20],
test = testSplit[-20],
cl=data_train$Absent_time, k=2)
knntable <- table(knn, testSplit$Absent_time)
#generate confusion matrix
cm_KNN <-  confusionMatrix(data = knntable, reference = testSplit[,-20], positive = "1")
cm_KNN
set.seed(1976)
dat1 <- dat[-1]
#scale
scale <- sapply(dat1, is.numeric)
dat1[scale] <- lapply(dat1[scale],scale)
p <- .6 # proportion of data for training
w <- sample(1:nrow(dat1), nrow(dat1)*p, replace=F)
data_train <-dat1[w,]
data_test <- dat1[-w,]
#Running the classifier
knn <- knn(data_train[-20],
test = testSplit[-20],
cl=data_train$Absent_time, k=2)
knntable <- table(knn, testSplit$Absent_time)
#generate confusion matrix
cm_KNN <-  confusionMatrix(data = knntable, reference = testSplit[,-20], positive = "1")
cm_KNN
set.seed(1976)
splitIndex <- createDataPartition(dat_v$Absent_time, p = .50,
list = FALSE,
times = 1)
trainSplit <- dat_v[ splitIndex,]
testSplit <- dat_v[-splitIndex,]
trainSplit$Absent_time <- as.factor(trainSplit$Absent_time)
trainSplit <- SMOTE(Absent_time ~ ., trainSplit, perc.over = 100, perc.under=200)
knn <- knn(trainSplit[,1:order[4,1]],
test = testSplit[,1:order[4,1]],
cl=trainSplit[,20], k=order[4,2])
knntable4 <- table(knn, testSplit[,20])
cm_KNN4 <-  confusionMatrix(data = knntable4, reference = testSplit[,20], positive = "1")
cm_KNN4
set.seed(1776)
dat1 <- dat[-1]
#scale
scale <- sapply(dat1, is.numeric)
dat1[scale] <- lapply(dat1[scale],scale)
p <- .6 # proportion of data for training
w <- sample(1:nrow(dat1), nrow(dat1)*p, replace=F)
data_train <-dat1[w,]
data_test <- dat1[-w,]
#Running the classifier
knn <- knn(data_train[-20],
test = testSplit[-20],
cl=data_train$Absent_time, k=2)
knntable <- table(knn, testSplit$Absent_time)
#generate confusion matrix
cm_KNN <-  confusionMatrix(data = knntable, reference = testSplit[,-20], positive = "1")
cm_KNN
set.seed(146)
dat1 <- dat[-1]
#scale
scale <- sapply(dat1, is.numeric)
dat1[scale] <- lapply(dat1[scale],scale)
p <- .6 # proportion of data for training
w <- sample(1:nrow(dat1), nrow(dat1)*p, replace=F)
data_train <-dat1[w,]
data_test <- dat1[-w,]
#Running the classifier
knn <- knn(data_train[-20],
test = testSplit[-20],
cl=data_train$Absent_time, k=2)
knntable <- table(knn, testSplit$Absent_time)
#generate confusion matrix
cm_KNN <-  confusionMatrix(data = knntable, reference = testSplit[,-20], positive = "1")
cm_KNN
set.seed(1976)
splitIndex <- createDataPartition(dat_v$Absent_time, p = .50,
list = FALSE,
times = 1)
trainSplit <- dat_v[ splitIndex,]
testSplit <- dat_v[-splitIndex,]
trainSplit$Absent_time <- as.factor(trainSplit$Absent_time)
trainSplit <- SMOTE(Absent_time ~ ., trainSplit, perc.over = 100, perc.under=200)
knn <- knn(trainSplit[,1:order[4,1]],
test = testSplit[,1:order[4,1]],
cl=trainSplit[,20], k=order[4,2])
knntable4 <- table(knn, testSplit[,20])
cm_KNN4 <-  confusionMatrix(data = knntable4, reference = testSplit[,20], positive = "1")
cm_KNN4
set.seed(146)
dat1 <- dat[-1]
#scale
scale <- sapply(dat1, is.numeric)
dat1[scale] <- lapply(dat1[scale],scale)
p <- .6 # proportion of data for training
w <- sample(1:nrow(dat1), nrow(dat1)*p, replace=F)
data_train <-dat1[w,]
data_test <- dat1[-w,]
#Running the classifier
knn <- knn(data_train[-20],
test = testSplit[-20],
cl=data_train$Absent_time, k=2)
knntable <- table(knn, testSplit$Absent_time)
#generate confusion matrix
cm_KNN <-  confusionMatrix(data = knntable, reference = testSplit[,-20], positive = "1")
cm_KNN
set.seed(1976)
dat1 <- dat[-1]
#scale
scale <- sapply(dat1, is.numeric)
dat1[scale] <- lapply(dat1[scale],scale)
p <- .6 # proportion of data for training
w <- sample(1:nrow(dat1), nrow(dat1)*p, replace=F)
data_train <-dat1[w,]
data_test <- dat1[-w,]
#Running the classifier
knn <- knn(data_train[-20],
test = testSplit[-20],
cl=data_train$Absent_time, k=2)
knntable <- table(knn, testSplit$Absent_time)
#generate confusion matrix
cm_KNN <-  confusionMatrix(data = knntable, reference = testSplit[,-20], positive = "1")
cm_KNN
set.seed(1976)
splitIndex <- createDataPartition(dat_v$Absent_time, p = .50,
list = FALSE,
times = 1)
trainSplit <- dat_v[ splitIndex,]
testSplit <- dat_v[-splitIndex,]
trainSplit$Absent_time <- as.factor(trainSplit$Absent_time)
trainSplit <- SMOTE(Absent_time ~ ., trainSplit, perc.over = 100, perc.under=200)
knn <- knn(trainSplit[,1:order[4,1]],
test = testSplit[,1:order[4,1]],
cl=trainSplit[,20], k=order[4,2])
knntable4 <- table(knn, testSplit[,20])
cm_KNN4 <-  confusionMatrix(data = knntable4, reference = testSplit[,20], positive = "1")
cm_KNN4
most_sig_stats
