---
title: "Statistical Learning Project"
output: html_notebook
---

Sarah, Pavel, Rose, Catherine, Shravya
East
Statistical Learning Project


```{r}
library(tidyverse)
library(reshape2)
library(readxl)
library(caret)
library(rpart) 
library(partykit) 
library(randomForest)
library(class)
```

```{r}

#Read in the data
dat <- read_excel("Absenteeism_at_work.xls")

#View the data
glimpse(dat)

```
##Pre-Processing Data
```{r}
#Set factored variables as factors
col <- c("ID", "Reason for absence", "Month of absence", "Day of the week", "Seasons", "Disciplinary failure", "Education", "Social drinker",   "Social smoker", "Pet", "Son")
dat[col] <- lapply(dat[col], as.factor)

#Rename the columns for easier use
colnames(dat) <- c("ID", "Reason", "Month", "Day", "Seasons", "Transportation_expense", "Distance", "Service_time", "Age", "Work_load", "Hit_target", "Disciplinary_failure", "Education", "Children", "Social_drinker", "Social_smoker", "Pet", "Weight", "Height", "BMI", "Absent_time")

#View the data
glimpse(dat)



```


```{r}
# Still need to reset levels on vrariables so ordered factors are graphed in order
```

```{r}
nums <- unlist(lapply(dat, is.numeric))  
dat.num <- dat[ , nums]

```
## EDA Response Variable

### Absent_time
```{r}
summary(dat$Absent_time)

```


```{r}
table(dat$Absent_time)
```

```{r}
#change variable represent missed time one day or greater
dat <- dat %>% mutate(Absent_time= ifelse(dat$Absent_time <=8,0,1))
```

```{r}
ggplot(data = dat,
       aes(x = Absent_time)) +
  geom_histogram() + 
  theme_minimal()
```
```{r}
dat %>%
  gather(-Absent_time, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Absent_time)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
```


## EDA Predictors

### ID
### Reason
### Month
### Day

```{r}
dat %>%
  gather(-Day, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Day)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
```


### Seasons

```{r}
#Scatterplots for variable 'Seasons'
dat %>%
  gather(-Seasons, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Seasons)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
```
### Transportation Expense

```{r}
summary(dat$Transportation_expense)
ggplot(data = dat,
       aes(x = Transportation_expense)) +
  geom_histogram(binwidth = 50) + 
  theme_minimal()
```

```{r}
dat %>%
  gather(-Transportation_expense, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Transportation_expense)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
# Possible positive correlation seen between distance and Transportation_expense
```

###Distance
```{r}
summary(dat$Distance)
ggplot(data = dat,
       aes(x = Distance)) +
  geom_histogram(binwidth = 5) + 
  theme_minimal()
```

```{r}
dat %>%
  gather(-Distance, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Distance)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
#Possible Positive correlation seen between distance and Transportation_expense
```

### Service Time
```{r}
ggplot(data = dat,
       aes(x = Service_time)) +
  geom_histogram() +
  theme_minimal()
```

```{r}
dat %>%
  gather(-Service_time, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Service_time)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")

```

### Age

```{r}
ggplot(data = dat,
       aes(x = Age)) +
  geom_histogram() + 
  theme_minimal()
```

```{r}
dat %>%
  gather(-Age, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Age)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")

```
### Workload

```{r}
summary(dat$Work_load)

ggplot(data = dat,
       aes(x = Work_load)) +
  geom_histogram(binwidth = 5000) + 
  theme_minimal()
```

```{r}
dat %>%
  gather(-Work_load, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Work_load)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
```

### Hit Target

```{r}
ggplot(data = dat,
       aes(x = Hit_target)) + 
  geom_histogram() +
  theme_minimal()
```

```{r}
dat %>%
  gather(-Hit_target, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Hit_target)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")

```
### Disciplinary Failure
dat %>%
  gather(-Disciplinary_failure, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Disciplinary_failure)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
  
### Education

dat %>%
  gather(-Education, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Education)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
  
### Children

dat %>%
  gather(-Children, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Children)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
### Social Drinker

dat %>%
  gather(-Social_drinker, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Social_drinker)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
  
###Social Smoker

```{r}
#Scatterplots for variable 'Social_smoker'
dat %>%
  gather(-Social_smoker, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Social_smoker)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
```


### Pet
### Weight

```{r}
dat %>%
  gather(-Weight, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Weight)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
```
### Height

dat.num %>%
  gather(-Height, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Height)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
### BMI

## Initial Method Testing

```{r}
# chose an odd number near the square root of size of the training set.

sqrt(444)

```


```{r}

####Note KNN code doesn't work yet, so comment out if need be but please insert code into this loop

R <- 50 # replications

# create the matrix to store values 1 row per model
err_matrix <- matrix(0, ncol=5, nrow=R)

sensitivity_matrix <- matrix(0, ncol=5, nrow=R)

fmeasure_matrix <- matrix(0, ncol=5, nrow=R)

gmean_matrix <- matrix(0, ncol=5, nrow=R)


set.seed(1876)
 

for (r in 1:R){
  
  # training test split
# subsetting data to training and testing data
p <- .6 # proportion of data for training
w <- sample(1:nrow(dat), nrow(dat)*p, replace=F)
data_train <-dat[w,] 
data_test <- dat[-w,]

  ########### knn

#Running the classifier

  knn <- knn(data_train[-21],
                       test = data_test[-21],
                       cl=data_train$Absent_time, k=21)
  

  # prediction    
#  yhat_knn <-  predict(#figure out what goes in here, data_test[,-21])
  
  # store the errors (change the 1 to whichever model you have)   
#  err_mat_bag[r,1] <-  mean(yhat_knn!=data_test[,21])
  
  #still need to add other errors
  
  
  ############# Other models follow
  
  
  # just a nice statement to tell you when each loop is done
  cat("Finished Rep",r, "\n")
}

```

#Logistic regression - Pavel
#I ran 2 models, a regular logistic and a boosted logistic regression. Results below:

#Transforming to Data Frame
```{r}
dat_1 <- as.data.frame(dat)
```

#Transforming variable 'Absent_time' into binomial:
```{r}
dat_1$Absent_time <- ifelse(dat_1$Absent_time <= 8, 'good', 'bad')

#Examining variable 'Absent_time'
table(dat_1$Absent_time)
```

#eliminating columns 1 through 5 since they do not provide any valuable information for prediction, 
#these are just variables that describe the data:
```{r}
dat_1 <- dat_1[,-c(1:5)]
dat_1$Absent_time <- as.factor(dat_1$Absent_time)
dat_1[1:15] <- scale(dat_1[1:15])

```
```{r}
#Setting number of repetitions
R = 50

# Creating  matrix to store the errors

test_error_A = matrix(0,ncol=1,nrow=R)
test_error_B = matrix(0,ncol=1,nrow=R)
```

```{r}
#A. Running regular logistic regression
set.seed(7359)
for (r in 1:R){
  
  ind = holdout(dat_1$Absent_time,ratio=3/5, mode='stratify') 
  
  tr_xy_A = dat_1[ind$tr,] # train set
  te_XY_A = dat_1[ind$ts,] # test set
  
 # running the actual model
  model_A = train(Absent_time ~ .,
                  data = tr_xy_A,
                  method = "glm", 
                  family = 'binomial') 
  
  yhat_A = predict(model_A, newdata = te_XY_A[,-16])
  
  cm_tr = (confusionMatrix(data = yhat_A, reference = te_XY_A[,16]))
  test_error_A[[r]] = sum(yhat_A!= te_XY_A[,16])/length( te_XY_A[,16])
}
```

```{r}
#B. Boosted logistic regression.
set.seed(7359)
for (r in 1:R){ # replication loop
  
  ind = holdout(dat_1$Absent_time,ratio=3/5, mode='stratify') # stratified train/test split
  
  tr_xy_B = dat_1[ind$tr,] # train set
  te_XY_B = dat_1[ind$ts,] # test set
  
  # running the actual model
  model_B = train(Absent_time ~ .,
                  data = tr_xy_B,
                  method = "LogitBoost")
  
  yhat_B = predict(model_B, newdata = te_XY_B[,-16])
  cm_tr_B = (confusionMatrix(data = yhat_B, reference = te_XY_B[,16]))
  test_error_B[[r]] = sum(yhat_B!= te_XY_B[,16])/length( te_XY_B[,16])  
}
```

#Metrics For regular and boosted logistic regression:
```{r}
#Sensitivity:
Sensitivity_A <- cm_tr$table[1,1]/(cm_tr$table[1,1]+cm_tr$table[2,1])

Sensitivity_B <- cm_tr_B$table[1,1]/(cm_tr_B$table[1,1]+cm_tr_B$table[2,1])

Sensitivity_metric <- as.data.frame(cbind(Sensitivity_A, Sensitivity_B)) %>% 
  `rownames<-`('Sensitivity')

#Renaming the columns:
colnames(Sensitivity_metric)[c(1,2)] <- c("Regular Logistic", "Boosted Logistic")

#Displaying Sensitivity
Sensitivity_metric
```

```{r}
#Computing F1:
#F1 for Regular logistic regression:

cm_tr1 <- as.matrix(cm_tr)
nc <- nrow(cm_tr1) # number of classes
diag <- diag(cm_tr1) # number of correctly classified instances per class 
rowsums <- apply(cm_tr1, 1, sum) # number of instances per class
colsums <- apply(cm_tr1, 2, sum) # number of predictions per class

precision <- diag / colsums 
recall <- diag / rowsums 

#The F-measure gives the harmonic mean of recall and precision 
f1_A <- 2 * precision * recall / (precision + recall) 

#F1 for Boosted Logistic Regression:

cm_tr2 <- as.matrix(cm_tr_B)

nc2 = nrow(cm_tr2) # number of classes
diag2 = diag(cm_tr2) # number of correctly classified instances per class 
rowsums2 = apply(cm_tr2, 1, sum) # number of instances per class
colsums2 = apply(cm_tr2, 2, sum) # number of predictions per class

precision2 = diag2 / colsums2 
recall2 = diag2 / rowsums2 

#The F-measure gives the harmonic mean of recall and precision 
f1_B = 2 * precision2 * recall2 / (precision2 + recall2) 

#Displaying F1 for both models:
data.frame(f1_A, f1_B)

```
```{r}
#Mean of errors:

mean_of_errors <- data.frame(mean(test_error_A), mean(test_error_B))
colnames(mean_of_errors)[c(1,2)] <- c("Regular Logistic", "Boosted Logistic")
mean_of_errors
```

```{r}
#Binding data for the ggplot:
box_matrix <- cbind(test_error_A, test_error_B)
colnames(box_matrix) <- c("test_error_A","test_error_B")
box_matrix <- melt(box_matrix)

#Displaying Box Plot for errors:
ggplot(data = data.frame(box_matrix), aes(x=Var2, y=value)) +
  geom_boxplot() + theme_bw() 
```

#Decision Tree - Sarah

```{r}
#read in the necessary packages
library(rpart)
library(partykit)
```

```{r}
data_train1 <- data_train
data_train1$Absent_time <- ifelse(data_train1$Absent_time <= 8, "good", "bad")
data_train1$Absent_time <- as.factor(data_train1$Absent_time)
data_train1 <- data_train1 %>% select(-ID)
data_test1 <- data_test
data_test1$Absent_time <- ifelse(data_test1$Absent_time <= 8, 1, 0)
data_test1$Absent_time <- as.factor(data_test1$Absent_time)
data_test1 <- data_test1 %>% select(-ID)
```

```{r}
#write a formula predicting Absent_time from all other variables
form <- as.formula(Absent_time ~ .)
#run a decision tree
tree1 <- rpart(formula = form, data = data_train1)
#view the decision tree
tree1

#view a plot of the decision tree
plot(as.party(tree1))
```

```{r}
tree_pred <- predict(object = tree1, newdata = data_test, type = "vector")

tree_pred

table(tree_pred, data_test$Absent_time)
```

```{r}
#Set seed to ensure replication
set.seed(22)
tunegrid <-  expand.grid(.cp = seq(.01:.1, by = .01)) #tune the complexity parameter

R <-  50 #set the number of replications

#create the error matrix to store values
err_mat_trees <-  matrix(0, ncol = 1, nrow = R)


for (r in 1:R){
  #training test split
  p <- .6   #proportion of the data for training
  train_id <- sample(1:nrow(dat), round(nrow(dat) * p), replace = FALSE)
  tree_train <- dat[train_id, ]
  tree_test <- dat[-train_id, ]
  
  #tree
  tree_mod = rpart(Absent_time ~ ., data = tree_train)
  
  #prediction
  yhat_tree = predict(tree_mod, tree_test, type = 'vector')
  
  #store the errors
  err_mat_trees[r, 1] = mean(yhat_tree != tree_test$Class)
  
  #Just a nice statement to tell you when each loop is done
  # cat("Finished Rep", r, "\n")
}

#view the error matrix for trees
# err_mat_trees

colnames(err_mat_trees) <- 'Trees'
err_mat_trees_melt <-  melt(as.data.frame(err_mat_trees))
colnames(err_mat_trees_melt) <-  c('Method', 'Error')

ggplot(err_mat_trees_melt, mapping = aes(x = Method, y = Error)) +
  geom_boxplot()
```
