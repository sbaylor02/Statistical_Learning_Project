####################
STOP; RUN ALL CODE FROM THROUGH After the EDA Response Variable SECTION PRIOR TO CODING FURTHER!!!!!!!!!!!!!!!!!!!!
#####################


---
title: "Statistical Learning Project"
output: html_notebook
---

Sarah, Pavel, Rose, Catherine, Shravya
East
Statistical Learning Project


```{r}
#load the necessary packages
library(plyr)
library(tidyverse)
library(reshape2)
library(readxl)
library(caret)
library(rpart) 
library(partykit) 
library(randomForest)
library(class)
library (rminer)
library(e1071)
library(mlbench)
library(plyr)
library(DMwR)

```

```{r}
#Read in the data
dat <- read_excel("Absenteeism_at_work.xls")

#View the data
glimpse(dat)
```

##Pre-Processing Data

```{r}
#Set factored variables as factors
col <- c("ID", "Reason for absence", "Month of absence", "Day of the week", "Seasons", "Disciplinary failure", "Education", "Social drinker",   "Social smoker")
#set all categorical variables as ordered factors
dat[col] <- lapply(dat[col], as.factor)
dat[col] <- lapply(dat[col], ordered)

#Rename the columns for easier use
colnames(dat) <- c("ID", "Reason", "Month", "Day", "Seasons", "Transportation_expense", "Distance", "Service_time", "Age", "Work_load", "Hit_target", "Disciplinary_failure", "Education", "Children", "Social_drinker", "Social_smoker", "Pet", "Weight", "Height", "BMI", "Absent_time")

#View the data
glimpse(dat)
```

```{r}
#create a list of the numeric variables in the data set
nums <- unlist(lapply(dat, is.numeric))  
#create a smaller data set of just numeric variables
dat.num <- dat[ , nums]
```

## EDA Response Variable

### Absent_time
```{r}
summary(dat$Absent_time)
```

```{r}
 count(dat$Absent_time)
```

```{r}
#change variable represent missed time one day or greater
dat <- dat %>% 
  mutate(Absent_time = ifelse(dat$Absent_time <= 8,0,1))
```

```{r}
#save Absent_time as a factor in the data set
dat$Absent_time <- as.factor(dat$Absent_time)
#Transforming to Data Frame
dat <- as.data.frame(dat)
```

```{r}
#plot the Absent_time
ggplot(data = dat,
       aes(x = Absent_time)) +
  geom_bar() + 
  theme_minimal()
```

```{r}
#plot all variables vs. Absent_time
dat %>%
  gather(-Absent_time, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Absent_time)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") +
  theme_minimal()
```


## EDA Predictors

### ID

```{r}
#frequency table by ID
dat %>% 
  count(ID)

#bar chart
dat %>% 
  ggplot(aes(x = ID)) +
  geom_bar() +
  theme_minimal()
```

```{r, warning=FALSE}
#ID
dat %>%
  gather(-ID, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = ID)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") + 
  theme_minimal()
```


### Reason

```{r}
#frequency table by Reason for Absence

  count(dat$Reason)

#bar chart
dat %>% filter(Absent_time==0) %>%
  ggplot(aes(x=Reason)) +
  geom_bar() +
  theme_minimal()
dat %>% filter(Absent_time==1) %>%
  ggplot(aes(x=Reason)) +
  geom_bar() +
  theme_minimal()
```

```{r, warning=FALSE}
#Reason for absence
table(dat %>%
  filter(Reason==0) %>%
  select(Absent_time))
  
```

### Month

```{r}
#frequency table by Month of Absence
dat %>% 
  count(Month)

#bar chart
dat %>% 
  ggplot(aes(x=Month)) +
  geom_bar() +
  theme_minimal()
```

```{r, warning=FALSE}
dat %>%
  gather(-Month, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Month)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") + 
  theme_minimal()
```

### Day

```{r}
#frequency table by Day of Absence
dat %>% 
  count(Day)

#bar chart
dat %>% 
  ggplot(aes(x=Month)) +
  geom_bar() +
  theme_minimal()
```


```{r, warning=FALSE}
dat %>%
  gather(-Day, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Day)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") +
  theme_minimal()
```


### Seasons

```{r}
#frequency table by Season of Absence
dat %>% 
  count(Seasons)

#bar chart
dat %>% 
  ggplot(aes(x=Seasons)) +
  geom_bar() +
  theme_minimal()
```

```{r, warning=FALSE}
#Scatterplots for variable 'Seasons'
dat %>%
  gather(-Seasons, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Seasons)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") +
  theme_minimal()
```

### Transportation Expense

```{r}
#summary of transportation expenses
summary(dat$Transportation_expense)

#histograph
ggplot(data = dat,
       aes(x = Transportation_expense)) +
  geom_histogram(binwidth = 50) + 
  theme_minimal()
```

```{r, warning=FALSE}
#Scatterplots for variable 'Transportation_expense'
dat %>%
  gather(-Transportation_expense, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Transportation_expense)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") +
  theme_minimal()
# Possible positive correlation seen between distance and Transportation_expense
```

###Distance

```{r}
#summary of distance
summary(dat$Distance)

#histogram
ggplot(data = dat,
       aes(x = Distance)) +
  geom_histogram(binwidth = 5) + 
  theme_minimal()
```

```{r, warning=FALSE}
#Scatterplots for variable 'Distance'
dat %>%
  gather(-Distance, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Distance)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") +
  theme_minimal()
#Possible Positive correlation seen between distance and Transportation_expense
```

### Service Time

```{r}
#summary for Service_time
summary(dat$Service_time)

#histogram
ggplot(data = dat,
       aes(x = Service_time)) +
  geom_histogram() +
  theme_minimal()
```

```{r, warning=FALSE}
#Scatterplots for variable 'Service_time'
dat %>%
  gather(-Service_time, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Service_time)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") +
  theme_minimal()
```

### Age

```{r}
#summary for Age
summary(dat$Age)

#histogram
ggplot(data = dat,
       aes(x = Age)) +
  geom_histogram() + 
  theme_minimal()
```

```{r, warning=FALSE}
#Scatterplots for variable 'Age'
dat %>%
  gather(-Age, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Age)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") +
  theme_minimal()
```

### Workload

```{r}
#summary for work load
summary(dat$Work_load)

#histogram
ggplot(data = dat,
       aes(x = Work_load)) +
  geom_histogram(binwidth = 5000) + 
  theme_minimal()
```

```{r, warning=FALSE}
#Scatterplots for variable 'Work_load'
dat %>%
  gather(-Work_load, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Work_load)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") +
  theme_minimal()
```

### Hit Target

```{r}
#summary for hit target
summary(dat$Hit_target)

#histogram
ggplot(data = dat,
       aes(x = Hit_target)) + 
  geom_histogram() +
  theme_minimal()
```

```{r, warning = FALSE}
#Scatterplots for variable 'Hit_target'
dat %>%
  gather(-Hit_target, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Hit_target)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") +
  theme_minimal()
```

### Disciplinary Failure

```{r}
#table for disciplinary failure
dat %>%
  count(Disciplinary_failure)

#bar chart
ggplot(data = dat,
       aes(x = Disciplinary_failure)) +
  geom_bar() +
  theme_minimal()
```


```{r, warning=FALSE}
#Scatterplots for variable 'Disciplinary_failure'
dat %>%
  gather(-Disciplinary_failure, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Disciplinary_failure)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") +
  theme_minimal()
```

### Education

```{r}
#table for education
dat %>%
  count(Education)

#bar chart
ggplot(data = dat,
       aes(x = Education)) +
  geom_bar() +
  theme_minimal()
```

```{r, warning=FALSE}
#Scatterplots for variable 'Education'
dat %>%
  gather(-Education, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Education)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") + 
  theme_minimal()
```

### Children

```{r}
#table for number of children
dat %>%
  count(Children)

#bar chart
ggplot(data = dat,
       aes(x = Children)) +
  geom_bar() +
  theme_minimal()
```


```{r, warning=FALSE}
#Scatterplots for variable 'Children'
dat %>%
  gather(-Children, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Children)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") +
  theme_minimal()
```

### Social Drinker

```{r}
#table for social drinking
dat %>%
  count(Social_drinker)

#bar chart
ggplot(data = dat,
       aes(x = Social_drinker)) + 
  geom_bar() +
  theme_minimal()
```


```{r, warning=FALSE}
#Scatterplots for variable 'Social_drinker'
dat %>%
  gather(-Social_drinker, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Social_drinker)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") +
  theme_minimal()
```

###Social Smoker

```{r}
#table for social smokers
dat %>%
  count(Social_smoker)

#bar chart
ggplot(data = dat,
       aes(x = Social_smoker)) + 
  geom_bar() +
  theme_minimal()
```


```{r, warning=FALSE}
#Scatterplots for variable 'Social_smoker'
dat %>%
  gather(-Social_smoker, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Social_smoker)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") + 
  theme_minimal()
```

### Pet

```{r}
#summary for pets
summary(dat$Pet)

#histogram
ggplot(data = dat,
       aes(x = Pet)) +
  geom_bar() +
  theme_minimal()
```


```{r, warning=FALSE}
#Scatterplots for variable 'Pet'
dat %>%
  gather(-Pet, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Pet)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") + 
  theme_minimal()
```

### Weight

```{r}
#summary of weight
summary(dat$Weight)

#histogram
ggplot(data = dat,
       aes(x = Weight)) +
  geom_histogram(bins = 15) +
  theme_minimal()
```


```{r, warning=FALSE}
#Scatterplots for variable 'Weight'
dat %>%
  gather(-Weight, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Weight)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") +
  theme_minimal()
```

### Height

```{r}
#summary of height
summary(dat$Height)

#histogram
ggplot(data = dat,
       aes(x = Height)) +
  geom_histogram(bins = 10) +
  theme_minimal()
```

```{r}
#Scatterplots for variable 'Height'
dat.num %>%
  gather(-Height, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Height)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") + 
  theme_minimal()
```

### BMI

```{r}
#summary for BMI
summary(dat$BMI)

#histogram
ggplot(data = dat,
       aes(x = BMI)) +
  geom_histogram(binwidth = 1) + 
  theme_minimal()
```

```{r, warning=FALSE}
#Scatterplots for variable 'BMI'
dat %>%
  gather(-BMI, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = BMI)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free") + 
  theme_minimal()
```

##Additional Preprocessing

```{r}
dat1 <- dat[-1]

#scale
scale <- sapply(dat1, is.numeric)
dat1[scale] <- lapply(dat1[scale],scale)
```


## Initial Method Testing


```{r, eval=FALSE, message=FALSE, warning=FALSE}
R <- 50 # replications

# create the matrix to store values 1 row per model
err_matrix <- matrix(0, ncol=5, nrow=R)

sensitivity_matrix <- matrix(0, ncol=5, nrow=R)

fmeasure_matrix <- matrix(0, ncol=5, nrow=R)

gmean_matrix <- matrix(0, ncol=5, nrow=R)

# these are optional but I like to see how the model did each run so I can check other output
KNNcm <- matrix(0, ncol=4, nrow=R)
glmcm <- matrix(0, ncol=4, nrow=R)
Treecm <- matrix(0, ncol=4, nrow=R)
rfcm <- matrix(0, ncol=4, nrow=R)
SVMcm <- matrix(0, ncol=4, nrow=R)

set.seed(1876)

for (r in 1:R){
  
# subsetting data to training and testing data
p <- .6 # proportion of data for training
w <- sample(1:nrow(dat1), nrow(dat1)*p, replace=F)
data_train <-dat1[w,] 
data_test <- dat1[-w,]
  
  ################################################################ knn

#Running the classifier

  knn <- knn(data_train[-20],
                       test = data_test[-20],
                       cl=data_train$Absent_time, k=2)
  
#predict doesn't work with KNN for factors
 knntable <- table(knn, data_test$Absent_time)
 
#generate confusion matrix ( the 1 tells the model we care about that output)
 cm_KNN <-  confusionMatrix(data = knntable, reference = data_test[,-20], positive = "1")
 
 KNNcm [[r,1]] <-  cm_KNN$table[1,1]
 KNNcm [[r,2]] <-  cm_KNN$table[1,2]
 KNNcm [[r,3]] <-  cm_KNN$table[2,1]
 KNNcm [[r,4]] <-  cm_KNN$table[2,2]
 
 err_matrix [[r,1]] <-  (cm_KNN$table[1,2]+cm_KNN$table[2,1])/nrow( data_test)
  
  # store the errors (change the 1 to whichever model you have)   
  
 sensitivity_matrix[[r, 1]] <- cm_KNN$byClass[1]
 
 fmeasure_matrix [[r, 1]] <- cm_KNN$byClass[7]
 
 gmean_matrix [[r, 1]] <- sqrt(cm_KNN$byClass[1]* cm_KNN$byClass[2])
  
  ################################################################### GLM
  

  model_glm_1 = suppressWarnings(
    train(Absent_time ~ .,
                      data = data_train,
                      method = "glm", 
                      family = 'binomial')
                      )
  
  yhat_glm = predict(model_glm_1, newdata = data_test[,-20])
  
  cm_glm = confusionMatrix(data = yhat_glm, reference = data_test[,20], positive = "1")
  
  glmcm [[r,1]] <-  cm_glm$table[1,1]
  glmcm [[r,2]] <-  cm_glm$table[1,2]
  glmcm [[r,3]] <-  cm_glm$table[2,1]
  glmcm [[r,4]] <-  cm_glm$table[2,2]
  
  err_matrix [[r,2]] <-  (cm_glm$table[1,2]+cm_glm$table[2,1])/nrow( data_test)
  
  # store the errors (change the 1 to whichever model you have)   
  
  sensitivity_matrix[[r, 2]] <- cm_glm$byClass[1]
  
  fmeasure_matrix [[r, 2]] <- cm_glm$byClass[7]
  
  gmean_matrix [[r, 2]] <- sqrt(cm_glm$byClass[1]* cm_glm$byClass[2])
  
  #####################################################Decision Tree

  tree_mod = rpart(Absent_time ~ ., data = data_train)
  
  #prediction
  yhat_tree = predict(tree_mod, data_test, type = 'class')
  
  #generate confusion matrix
 cm_tree <-  confusionMatrix(data = table(yhat_tree, data_test$Absent_time), reference = data_test[,-20], positive = "1")
 
 Treecm[[r,1]] <-  cm_tree$table[1,1]
 Treecm[[r,2]] <-  cm_tree$table[1,2]
 Treecm[[r,3]] <-  cm_tree$table[2,1]
 Treecm[[r,4]] <-  cm_tree$table[2,2]
  
  #store the errors
  err_matrix[r, 3] = mean(yhat_tree != data_test$Absent_time)
  
    # store the errors 
  
 sensitivity_matrix[[r, 3]] <- cm_tree$byClass[1]
 
 cm_tree$byClass[1]
 
 fmeasure_matrix[[r, 3]] <- cm_tree$byClass[7]
 
 gmean_matrix[[r, 3]] <- sqrt(cm_tree$byClass[1]* cm_tree$byClass[2])
 
 #################################################### RF
 
   rf <- randomForest(Absent_time ~.,
                              data=data_train,
                              mtry=6,
                              ntree=50,
                              na.action=na.roughfix)
 
  yhat_rf = predict(rf, newdata = data_test, type= 'class')

  cm_rf = confusionMatrix(data = yhat_rf, reference = data_test[,20], positive = "1")


  rfcm [[r,1]] <-  cm_rf$table[1,1]
  rfcm [[r,2]] <-  cm_rf$table[1,2]
  rfcm [[r,3]] <-  cm_rf$table[2,1]
  rfcm [[r,4]] <-  cm_rf$table[2,2]
  
 err_matrix [[r,4]] <-  (cm_glm$table[1,2]+cm_glm$table[2,1])/nrow( data_test)
  
 sensitivity_matrix[[r, 4]] <- cm_rf$byClass[1]
 
 fmeasure_matrix[[r, 4]] <- cm_rf$byClass[7]
 
 gmean_matrix[[r, 4]] <- sqrt(cm_rf$byClass[1]* cm_rf$byClass[2])
  
  ################################################################ SVM
  
  csvm_absent =   svm(Absent_time~., data=data_train,
                   type='C-classification')
  
  #prediction
  y_hat_csvm = predict(csvm_absent, data_test[,-20])
  
#generate confusion matrix ( the 1 tells the model we care about that output)
  cm_SVM = confusionMatrix(data = y_hat_csvm, reference = data_test[,20], positive = "1")
  
  SVMcm [[r,1]] <-  cm_SVM$table[1,1]
  SVMcm [[r,2]] <-  cm_SVM$table[1,2]
  SVMcm [[r,3]] <-  cm_SVM$table[2,1]
  SVMcm [[r,4]] <-  cm_SVM$table[2,2]
 
  # store the errors (change the 1 to whichever model you have)
  err_matrix[r,5] = (cm_SVM$table[1,2]+cm_SVM$table[2,1])/nrow(data_test)
  
  sensitivity_matrix[[r, 5]] <- cm_SVM$byClass[1]
  
  fmeasure_matrix [[r, 5]] <- cm_SVM$byClass[7]
  
  gmean_matrix [[r, 5]] <- sqrt(cm_SVM$byClass[1]* cm_SVM$byClass[2])
 
#statement indicates where in loop
  #cat("Finished Rep",r, "\n")
}

```

Change the matrix names to make easier to interpret

```{r}
#rename the columns in the model
colnames(err_matrix) <- c("KNN","glm", "tree","RF", 'SVM')

colnames(sensitivity_matrix)<- c("KNN","glm", "tree","RF", 'SVM')

colnames(fmeasure_matrix) <- c("KNN","glm", "tree","RF", 'SVM')

colnames(gmean_matrix) <- c("KNN","glm", "tree","RF", 'SVM')


#rename the columns
colnames(KNNcm) <- c("True Negative","False Negative", "False Positive","True Positive")

colnames(glmcm) <- c("True Negative","False Negative", "False Positive","True Positive")

colnames(SVMcm) <- c("True Negative","False Negative", "False Positive","True Positive")
```

save output
```{r eval=FALSE}
save(err_matrix, file='errmatrix.RData')
save(sensitivity_matrix, file='sensmatrix.RData')
save(fmeasure_matrix, file='fmeasmatrix.RData')
save(gmean_matrix, file='gmeanmatrix.RData')
```
 
load output
```{r}
load( file='errmatrix.RData')
load( file='sensmatrix.RData')
load( file='fmeasmatrix.RData')
load( file='gmeanmatrix.RData')
```
 
```{r}
err_graph <- melt(err_matrix)

ggplot(err_graph, 
       aes(x=Var2, y=value)) +
  geom_boxplot() +
  theme_minimal()
```

```{r}
sens_graph <- melt(sensitivity_matrix)

ggplot(sens_graph, 
       aes(x=Var2, y=value)) +
  geom_boxplot() +
  theme_minimal()
```

```{r}
fmeas_graph <- melt(fmeasure_matrix)

ggplot(fmeas_graph, 
       aes(x=Var2, y=value)) +
  geom_boxplot() + 
  theme_minimal()
```

```{r}
gmean_graph <- melt(gmean_matrix)

ggplot(gmean_graph, 
       aes(x=Var2, y=value)) +
  geom_boxplot() +
  theme_minimal()
```


##KNN Optimization
### Attempt 1
```{r}
###Optimizing the KNN

#For the tunning of the KNN model, we are going to create another traning/test data sets.

#scaling the data:
dat_v <- dat #we are going to use dat_v for the manipulation

dat_v[c(6:11, 14, 17:20)] <- lapply(dat_v[c(6:11, 14, 17:20)], function(x) c(scale(x)))
str(dat_v)
```

```{r}
#predicting class:
AB_class <- dat_v[, 21]
names(AB_class) <- c(1:nrow(dat_v))
dat_v$ID <- c(1:nrow(dat_v))

dat_v <- dat_v[1:737,]
nrow(dat_v)
rand_permute <- sample(x = nrow(dat_v), size = nrow(dat_v))

all_id_random <- dat_v[rand_permute, "ID"]
dat_v <- dat_v[,-1] #remove ID
```

```{r}
#random samples for training test
validate_id <- as.character(all_id_random[1:248])
training_id <- as.character(all_id_random[249:737])

dat_v_train <- dat_v[training_id, ]
dat_v_val <- dat_v[validate_id, ]
AB_class_train <- AB_class[training_id]
AB_class_val <- AB_class[validate_id]
table(AB_class_train)
```

```{r}
#Study significance of the variables
exp_vars <- names(dat_v_train)
exp_var_fstat <- as.numeric(rep(NA, times = 20))
names(exp_var_fstat) <- exp_vars

for (j in 1:length(exp_vars)) {
  exp_var_fstat[exp_vars[j]] <- summary(lm(as.formula(paste(exp_vars[j], " ~ AB_class_train")), 
                                           data = dat_v_train))$fstatistic[1]
}

exp_var_fstat

exp_var_fstat2 <- sapply(exp_vars, function(x) {
  summary(lm(as.formula(paste(x, " ~ AB_class_train")), data = dat_v_train))$fstatistic[1]
})
exp_var_fstat2

names(exp_var_fstat2) <- exp_vars
```

```{r}
#plyr version of the fit

wbcd_df_L <- lapply(exp_vars, function(x) {
  df <- data.frame(sample = rownames(dat_v_train), 
                   variable = x, value = dat_v_train[, x], 
                   class = AB_class_train)
  df
})
head(wbcd_df_L[[1]])

names(wbcd_df_L) <- exp_vars
```

```{r}
library(plyr)
var_sig_fstats <- laply(wbcd_df_L, function(df) {
  fit <- lm(value ~ class, data = df)
  f <- summary(fit)$fstatistic[1]
  f
})

names(var_sig_fstats) <- names(wbcd_df_L)
var_sig_fstats[1:3]
```

```{r}
#Conclusions about significance of the variables

most_sig_stats <- sort(var_sig_fstats, decreasing = T)
most_sig_stats[1:5]

#As per 'most_sig_stats' the 5 most significant variables for the prediction are: 
#'Seasons', 'Reason', 'Service_time', 'Month' and 'work_load'

#Re ordering variables by significance:

dat_v_train_ord <- dat_v_train[, names(most_sig_stats)]
str(dat_v_train_ord)

  
dat_v_val_ord <- dat_v_val[, names(dat_v_train_ord)]
str(dat_v_val_ord)
```

```{r}
#Monte Carlo Validation:

size <- length(training_id)
(2/3) * length(training_id)

training_family_L <- lapply(1:500, function(j) {
  perm <- sample(1:size, size = size, replace = F)
  shuffle <- training_id[perm]
  trn <- shuffle[1:326]
  trn
})

validation_family_L <- lapply(training_family_L, 
                              function(x) setdiff(training_id, x))
```

```{r}
#Finding an optimal set of variables and optimal k

N <- seq(from = 2, to = 19, by = 1)
sqrt(length(training_family_L[[1]]))
K <- seq(from = 1, to = 15, by = 1)
times <- 500 * length(N) * length(K)
```

```{r}
#Execution of the test with loops

paramter_errors_df <- data.frame(mc_index = as.integer(rep(NA, times = times)), 
                                 var_num = as.integer(rep(NA, times = times)), 
                                 k = as.integer(rep(NA, times = times)), 
                                 error = as.numeric(rep(NA, times = times)))
```

```{r}
#Core knn_model:
# j = index, n = length of range of variables, k=k
core_knn <- function(j, n, k) {
  knn_predict <- knn(train = dat_v_train_ord[training_family_L[[j]], 1:n], 
                     test = dat_v_train_ord[validation_family_L[[j]], 1:n], 
                     cl = AB_class_train[training_family_L[[j]]], 
                     k = k)
  tbl <- table(knn_predict, AB_class_train[validation_family_L[[j]]])
  err <- (tbl[1, 2] + tbl[2, 1])/(tbl[1, 2] + tbl[2, 1]+tbl[1, 1] + tbl[2, 2])
  err
}


param_df1 <- merge(data.frame(mc_index = 1:500), data.frame(var_num = N))
param_df <- merge(param_df1, data.frame(k = K))

knn_err_est_df <- ddply(param_df[1:times, ], .(mc_index, var_num, k), function(df) {
  err <- core_knn(df$mc_index[1], df$var_num[1], df$k[1])
  err
})

head(knn_err_est_df)
names(knn_err_est_df)[4] <- "error"

mean_errs_df <- ddply(knn_err_est_df, .(var_num, k), function(df) mean(df$error))
head(mean_errs_df)
names(mean_errs_df)[3] <- "mean_error"
```

```{r}
ggplot(data = mean_errs_df, 
       aes(x = var_num, y = k, 
           color = mean_error)) + 
  geom_point(size = 5) + 
  theme_minimal()
```

```{r}
#This is the model that produces the lowest mean error var_num = 6 and k = 1:
mean_errs_df[which.min(mean_errs_df$mean_error), ]

mean_errs_df %>% arrange(mean_error)
```


```{r}


#eventually run old to compare with new. 
#We see that although error lower, other metrics hurt. We care about identifying >8 hours  so modify
```
#Attempt 2: Repeat with sensitivity
```{r}

core_knn_sen <- function(j, n, k) {
  knn_predict <- knn(train = dat_v_train_ord[training_family_L[[j]], 1:n], 
                     test = dat_v_train_ord[validation_family_L[[j]], 1:n], 
                     cl = AB_class_train[training_family_L[[j]]], 
                     k = 1)

  tbl <- table(knn_predict, AB_class_train[validation_family_L[[j]]])
  
  #generate confusion matrix ( the 1 tells the model we care about that output)
  cm_KNN <-  confusionMatrix(data = tbl, reference =AB_class_train[validation_family_L[[j]]], positive = "1")
  
  sen <- cm_KNN$byClass[1]
  sen
}
```

```{r}
param_df1_2 <- merge(data.frame(mc_index = 1:500), data.frame(var_num = N))
param_df_2 <- merge(param_df1_2, data.frame(k = K))

knn_err_est_df_2 <- ddply(param_df_2[1:times, ], .(mc_index, var_num, k), function(df) {
  sen <- core_knn_sen(df$mc_index[1], df$var_num[1], df$k[1])
  sen
})

head(knn_err_est_df_2)
names(knn_err_est_df_2)[4] <- "Sensitivity"

mean_sens_df <- ddply(knn_err_est_df_2, .(var_num, k), function(df) mean(df$Sensitivity))
head(mean_sens_df)
names(mean_sens_df)[3] <- "mean_sensitivity"
```

```{r}
ggplot(data = mean_sens_df, 
       aes(x = var_num, y = k, 
           color = mean_sensitivity)) + 
  geom_point(size = 5) + 
  theme_minimal()
```

```{r}
#This is the model that produces the lowest mean error var_num = 10 and k = 3:
mean_sens_df[which.max(mean_sens_df$mean_sensitivity), ]

mean_sens_df %>% arrange(desc(mean_sensitivity))
```

Test with different test/training splits
```{r}
R <- 100 # replications

# create the matrix to store values 1 row per model
err_matrix_opt <- matrix(0, ncol=2, nrow=R)

sensitivity_matrix_opt <- matrix(0, ncol=2, nrow=R)

fmeasure_matrix_opt <- matrix(0, ncol=2, nrow=R)

gmean_matrix_opt <- matrix(0, ncol=2, nrow=R)

# these are optional but I like to see how the model did each run so I can check other output
KNNcm <- matrix(0, ncol=4, nrow=R)

dat_smaller <- dat[, names(dat_v_train_ord)]
dat_smaller[,20] <- dat$Absent_time


dat_smaller <- dat_smaller[1:737,] # remove lines with non-meaningful data

scale <- sapply(dat_smaller, is.numeric)
dat_smaller[scale] <- lapply(dat_smaller[scale],scale)
head(dat_smaller)
```

```{r}
set.seed(1876)


for (r in 1:R){
  
  # subsetting data to training and testing data
  p <- .6 # proportion of data for training
  w <- sample(1:nrow(dat_smaller), nrow(dat_smaller)*p, replace=F)
  data_train <-dat_smaller[w,] 
  data_test <- dat_smaller[-w,]
  
  ################################################################ knn
  
  #Running the classifier
  
  knn <- knn(data_train[,1:2],
             test = data_test[,1:2],
             cl=data_train[,20], k=5)
  
  #predict doesn't work with KNN for factors
  knntable <- table(knn, data_test[,20])
  
  #generate confusion matrix ( the 1 tells the model we care about that output)
  cm_KNN <-  confusionMatrix(data = knntable, reference = data_test[,1:2], positive = "1")
  
  KNNcm [[r,1]] <-  cm_KNN$table[1,1]
  KNNcm [[r,2]] <-  cm_KNN$table[1,2]
  KNNcm [[r,3]] <-  cm_KNN$table[2,1]
  KNNcm [[r,4]] <-  cm_KNN$table[2,2]
  
  err_matrix_opt [[r,1]] <-  (cm_KNN$table[1,2]+cm_KNN$table[2,1])/nrow( data_test)
  
  # store the errors (change the 1 to whichever model you have)   
  
  sensitivity_matrix_opt[[r, 1]] <- cm_KNN$byClass[1]
  
  fmeasure_matrix_opt [[r, 1]] <- cm_KNN$byClass[7]
  
  gmean_matrix_opt [[r, 1]] <- sqrt(cm_KNN$byClass[1]* cm_KNN$byClass[2])
  
  cat("Finished Rep",r, "\n")
}
colnames(sensitivity_matrix_opt)<- c("KNN", "other")
graph_sens <- melt(sensitivity_matrix_opt)
```

```{r}
graph <- ggplot(graph_sens,
                aes(x=Var2, y=value) ) + 
  geom_boxplot() +
  theme_minimal()

graph
```

```{r}
colnames(err_matrix_opt)<- c("KNN", "other")
graph_err <- melt(err_matrix_opt)

graph <- ggplot(graph_err,
                aes(x=Var2, y=value) ) + 
  geom_boxplot() +
  theme_minimal()

graph
```
Still do not see significant improvement in model

# Using SMOTE to optimize

```{r}
set.seed(1876)

dat <- read_excel("Absenteeism_at_work.xls")
col <- c("ID", "Reason for absence", "Month of absence", "Day of the week", "Seasons", "Disciplinary failure", "Education", "Social drinker",   "Social smoker")
dat[col] <- lapply(dat[col], as.factor)
colnames(dat) <- c("ID", "Reason", "Month", "Day", "Seasons", "Transportation_expense", "Distance", "Service_time", "Age", "Work_load", "Hit_target", "Disciplinary_failure", "Education", "Children", "Social_drinker", "Social_smoker", "Pet", "Weight", "Height", "BMI", "Absent_time")


nums <- unlist(lapply(dat, is.numeric))  
dat.num <- dat[ , nums]

#change variable represent missed time one day or greater
dat <- dat %>% mutate(Absent_time= ifelse(dat$Absent_time <=8,0,1))
str(dat)
dat$Absent_time <- as.factor(dat$Absent_time)
#Transforming to Data Frame
dat <- as.data.frame(dat)

str(dat)

###Optimizing the KNN

#For the tunning of the KNN model, we are going to create another traning/test data sets.

#scaling the data:
dat_v <- dat #we are going to use dat_v for the manipulation
scale <- sapply(dat_v, is.numeric)
dat_v[scale] <- lapply(dat_v[scale],scale)
head(dat_v)


#predicting class:
AB_class <- dat_v[, 21]
names(AB_class) <- c(1:nrow(dat_v))
dat_v$ID <- c(1:nrow(dat_v))

dat_v <- dat_v[1:737,]
nrow(dat_v)
rand_permute <- sample(x = nrow(dat_v), size = nrow(dat_v))

all_id_random <- dat_v[rand_permute, "ID"]
dat_v <- dat_v[,-1] #remove ID

#######

splitIndex <- createDataPartition(dat_v$Absent_time, p = .50,
                                  list = FALSE,
                                  times = 1)

trainSplit <- dat_v[ splitIndex,]
testSplit <- dat_v[-splitIndex,]

trainSplit$Absent_time <- as.factor(trainSplit$Absent_time)
trainSplit <- SMOTE(Absent_time ~ ., trainSplit, perc.over = 100, perc.under=200)

prop.table(table(trainSplit$Absent_time))

#######

#labels to make inserted code work
validate_id <- c(1:nrow(testSplit))
training_id <- c(1:nrow(trainSplit))

#rename to work with rest of code
dat_v_train <- trainSplit
dat_v_val <- testSplit
AB_class_train <- trainSplit$Absent_time
AB_class_val <- testSplit$Absent_time
#Confirms data comes out as expected
table(AB_class_train)

#Study significance of the variables

rf <- randomForest(Absent_time ~.,
                   data=dat_v_train,
                   mtry=6,
                   ntree=50,
                   na.action=na.roughfix)

impfact <- importance(rf)

impfact <- as.list(impfact)
names(impfact) <- colnames(dat_v[,-20])
impfact2 <- unlist(impfact)


most_sig_stats <- names(sort(desc(impfact2)))

#As per 'most_sig_stats' the 5 most significant variables for the prediction are: 
#'Seasons', 'Reason', 'Service_time', 'Month' and 'work_load'

#Re ordering variables by significance:

dat_v_train_ord <- dat_v_train[ c(most_sig_stats)]
str(dat_v_train_ord)

  
dat_v_val_ord <- dat_v_val[, names(dat_v_train_ord)]
str(dat_v_val_ord)

#######################
#######################

#Monte Carlo Validation:

size <- nrow(dat_v_train)
sub <- (2/3) * nrow(dat_v_train)

training_family_L <- lapply(1:500, function(j) {
  perm <- sample(1:size, size = size, replace = F)
  shuffle <- training_id[perm]
  trn <- shuffle[1:sub]
  trn
})

validation_family_L <- lapply(training_family_L, 
                              function(x) setdiff(training_id, x))

#Finding an optimal set of variables and optimal k

N <- seq(from = 2, to = 19, by = 1)
sqrt(length(training_family_L[[1]]))
K <- seq(from = 1, to = 19, by = 2)
times <- 500 * length(N) * length(K)

#Execution of the test with loops

paramter_errors_df <- data.frame(mc_index = as.integer(rep(NA, times = times)), 
                                 var_num = as.integer(rep(NA, times = times)), 
                                 k = as.integer(rep(NA, times = times)), 
                                 error = as.numeric(rep(NA, times = times)))

#Core knn_model:
# j = index, n = length of range of variables, k=k
#core_knn <- function(j, n, k) {
 # knn_predict <- knn(train = dat_v_train_ord[training_family_L[[j]], 1:n], 
  #                   test = dat_v_train_ord[validation_family_L[[j]], 1:n], 
   #                  cl = AB_class_train[training_family_L[[j]]], 
    #                 k = k)
#  tbl <- table(knn_predict, AB_class_train[validation_family_L[[j]]])
 # err <- (tbl[1, 2] + tbl[2, 1])/(tbl[1, 2] + tbl[2, 1]+tbl[1, 1] + tbl[2, 2])
  #err}


param_df1 <- merge(data.frame(mc_index = 1:500), data.frame(var_num = N))
param_df <- merge(param_df1, data.frame(k = K))

#knn_err_est_df <- ddply(param_df[1:times, ], .(mc_index, var_num, k), function(df) {
 # err <- core_knn(df$mc_index[1], df$var_num[1], df$k[1])
  #err
#})

#head(knn_err_est_df)
#names(knn_err_est_df)[4] <- "error"

#mean_errs_df <- ddply(knn_err_est_df, .(var_num, k), function(df) mean(df$error))
#head(mean_errs_df)
#names(mean_errs_df)[3] <- "mean_error"

#ggplot(data = mean_errs_df, aes(x = var_num, y = k, color = mean_error)) + geom_point(size = 5) + theme_bw()

#mean_errs_df[which.min(mean_errs_df$mean_error), ]

#mean_errs_df %>% arrange(mean_error)



#eventually run old to compare with new. 
#We see that although error lower, other metrics hurt. We care about identifying >8 hours  so modify

#Repeat with sensitivity

N <- seq(from = 2, to = 19, by = 1)
sqrt(length(training_family_L[[1]]))
K <- seq(from = 1, to = 19, by = 2)
times <- 500 * length(N) * length(K)

core_knn_sen <- function(j, n, k) {
  knn_predict <- knn(train = dat_v_train_ord[training_family_L[[j]], 1:n], 
                     test = dat_v_train_ord[validation_family_L[[j]], 1:n], 
                     cl = AB_class_train[training_family_L[[j]]], 
                     k = k)

  tbl <- table(knn_predict, AB_class_train[validation_family_L[[j]]])
  
  #generate confusion matrix ( the 1 tells the model we care about that output)
  #cm_KNN <-  confusionMatrix(data = tbl, reference =AB_class_train[validation_family_L[[j]]], positive = "1")
  
  sen <- (tbl[2, 2] )/(tbl[1, 2] + tbl[2, 2])
  sen
}


param_df1_2 <- merge(data.frame(mc_index = 1:500), data.frame(var_num = N))
param_df_2 <- merge(param_df1_2, data.frame(k = K))

knn_err_est_df_2 <- ddply(param_df_2[1:times, ], .(mc_index, var_num, k), function(df) {
  sen <- core_knn_sen(df$mc_index[1], df$var_num[1], df$k[1])
  sen
})

head(knn_err_est_df_2)
names(knn_err_est_df_2)[4] <- "Sensitivity"

mean_sens_df <- ddply(knn_err_est_df_2, .(var_num, k), function(df) mean(df$Sensitivity))
head(mean_sens_df)
names(mean_sens_df)[3] <- "mean_sensitivity"

ggplot(data = mean_sens_df, aes(x = var_num, y = k, color = mean_sensitivity)) + geom_point(size = 5) + 
  theme_bw()


mean_sens_df[which.max(mean_sens_df$mean_sensitivity), ]

order <- mean_sens_df %>% arrange(desc(mean_sensitivity))



```

```{r eval=FALSE}
save(mean_sens_df, file='mean_sens_df.RData')
```


```{r eval=FALSE}
R <- 100 # replications


# create the matrix to store values 1 row per model
err_matrix_opt <- matrix(0, ncol=5, nrow=R)

sensitivity_matrix_opt <- matrix(0, ncol=5, nrow=R)

fmeasure_matrix_opt <- matrix(0, ncol=5, nrow=R)

gmean_matrix_opt <- matrix(0, ncol=5, nrow=R)

# these are optional but I like to see how the model did each run so I can check other output
KNNcm <- matrix(0, ncol=4, nrow=R)
KNNcm2 <- matrix(0, ncol=4, nrow=R)
KNNcm3 <- matrix(0, ncol=4, nrow=R)
KNNcm4 <- matrix(0, ncol=4, nrow=R)
KNNcm5 <- matrix(0, ncol=4, nrow=R)

set.seed(1876)

for (r in 1:R){
  
  # subsetting data to training and testing data
  splitIndex <- createDataPartition(dat_v$Absent_time, p = .50,
                                    list = FALSE,
                                    times = 1)
  
  trainSplit <- dat_v[ splitIndex,]
  testSplit <- dat_v[-splitIndex,]
  
  trainSplit$Absent_time <- as.factor(trainSplit$Absent_time)
  trainSplit <- SMOTE(Absent_time ~ ., trainSplit, perc.over = 100, perc.under=200)
  ################################################################ knn
  
  #Running the classifier
  
  #option 1
  
  knn <- knn(trainSplit[,1:order[1,1]],
             test = testSplit[,1:order[1,1]],
             cl=trainSplit[,20], k=order[1,2])
  
  #predict doesn't work with KNN for factors
  knntable <- table(knn, testSplit[,20])
  
  cm_KNN <-  confusionMatrix(data = knntable, reference = testSplit[,20], positive = "1")
  
  KNNcm [[r,1]] <-  cm_KNN$table[1,1]
  KNNcm [[r,2]] <-  cm_KNN$table[1,2]
  KNNcm [[r,3]] <-  cm_KNN$table[2,1]
  KNNcm [[r,4]] <-  cm_KNN$table[2,2]
  
  err_matrix_opt [[r,1]] <-  (cm_KNN$table[1,2]+cm_KNN$table[2,1])/nrow(testSplit)
  
  # store the errors 
  
  sensitivity_matrix_opt[[r, 1]] <- cm_KNN$byClass[1]
  
  fmeasure_matrix_opt [[r, 1]] <- cm_KNN$byClass[7]
  
  gmean_matrix_opt [[r, 1]] <- sqrt(cm_KNN$byClass[1]* cm_KNN$byClass[2])
  
  ######################
  #option 2
  
  knn <- knn(trainSplit[,1:order[2,1]],
             test = testSplit[,1:order[2,1]],
             cl=trainSplit[,20], k=order[2,2])
  
  #predict doesn't work with KNN for factors
  knntable2 <- table(knn, testSplit[,20])
  
  cm_KNN2 <-  confusionMatrix(data = knntable2, reference = testSplit[,20], positive = "1")
  
  KNNcm2 [[r,1]] <-  cm_KNN2$table[1,1]
  KNNcm2 [[r,2]] <-  cm_KNN2$table[1,2]
  KNNcm2 [[r,3]] <-  cm_KNN2$table[2,1]
  KNNcm2 [[r,4]] <-  cm_KNN2$table[2,2]
  
  err_matrix_opt [[r,2]] <-  (cm_KNN2$table[1,2]+cm_KNN2$table[2,1])/nrow(testSplit)
  
  sensitivity_matrix_opt[[r, 2]] <- cm_KNN2$byClass[1]
  
  fmeasure_matrix_opt [[r, 2]] <- cm_KNN2$byClass[7]
  
  gmean_matrix_opt [[r, 2]] <- sqrt(cm_KNN2$byClass[1]* cm_KNN2$byClass[2])
  
  ##########
  #option 3
  
  knn <- knn(trainSplit[,1:order[3,1]],
             test = testSplit[,1:order[3,1]],
             cl=trainSplit[,20], k=order[3,2])
  
  #predict doesn't work with KNN for factors
  knntable <- table(knn, testSplit[,20])
  
  cm_KNN3 <-  confusionMatrix(data = knntable, reference = testSplit[,20], positive = "1")
  
  KNNcm3 [[r,1]] <-  cm_KNN3$table[1,1]
  KNNcm3 [[r,2]] <-  cm_KNN3$table[1,2]
  KNNcm3 [[r,3]] <-  cm_KNN3$table[2,1]
  KNNcm3 [[r,4]] <-  cm_KNN3$table[2,2]
  
  err_matrix_opt [[r,3]] <-  (cm_KNN3$table[1,2]+cm_KNN3$table[2,1])/nrow(testSplit)
  
  sensitivity_matrix_opt[[r, 3]] <- cm_KNN3$byClass[1]
  
  fmeasure_matrix_opt [[r, 3]] <- cm_KNN3$byClass[7]
  
  gmean_matrix_opt [[r, 3]] <- sqrt(cm_KNN3$byClass[1]* cm_KNN3$byClass[2])
  
  ################
  #option 4
  
  knn <- knn(trainSplit[,1:order[4,1]],
             test = testSplit[,1:order[4,1]],
             cl=trainSplit[,20], k=order[4,2])
  
  #predict doesn't work with KNN for factors
  knntable4 <- table(knn, testSplit[,20])
  
  cm_KNN4 <-  confusionMatrix(data = knntable4, reference = testSplit[,20], positive = "1")
  
  KNNcm4 [[r,1]] <-  cm_KNN4$table[1,1]
  KNNcm4 [[r,2]] <-  cm_KNN4$table[1,2]
  KNNcm4 [[r,3]] <-  cm_KNN4$table[2,1]
  KNNcm4 [[r,4]] <-  cm_KNN4$table[2,2]
  
  err_matrix_opt [[r,4]] <-  (cm_KNN4$table[1,2]+cm_KNN4$table[2,1])/nrow(testSplit)
  
  # store the errors  
  
  sensitivity_matrix_opt[[r, 4]] <- cm_KNN4$byClass[1]
  
  fmeasure_matrix_opt [[r, 4]] <- cm_KNN4$byClass[7]
  
  gmean_matrix_opt [[r, 4]] <- sqrt(cm_KNN4$byClass[1]* cm_KNN4$byClass[2])
  
  #####################
  #option 5
  
  knn <- knn(trainSplit[,1:order[5,1]],
             test = testSplit[,1:order[5,1]],
             cl=trainSplit[,20], k=order[5,2])
  
  knntable5 <- table(knn, testSplit[,20])
  
  cm_KNN5 <-  confusionMatrix(data = knntable5, reference = testSplit[,20], positive = "1")
  
  KNNcm5 [[r,1]] <-  cm_KNN5$table[1,1]
  KNNcm5 [[r,2]] <-  cm_KNN5$table[1,2]
  KNNcm5 [[r,3]] <-  cm_KNN5$table[2,1]
  KNNcm5 [[r,4]] <-  cm_KNN5$table[2,2]
  
  err_matrix_opt [[r,5]] <-  (cm_KNN5$table[1,2]+cm_KNN5$table[2,1])/nrow( testSplit)
  
  # store the errors  
  
  sensitivity_matrix_opt[[r, 5]] <- cm_KNN5$byClass[1]
  
  fmeasure_matrix_opt [[r, 5]] <- cm_KNN5$byClass[7]
  
  gmean_matrix_opt [[r, 5]] <- sqrt(cm_KNN5$byClass[1]* cm_KNN5$byClass[2])
  
  cat("Finished Rep",r, "\n")
}
colnames(sensitivity_matrix_opt)<- c("mod1","mod2","mod3","mod4","mod5")
graph_sens <- melt(sensitivity_matrix_opt)

ggplot(graph_sens,aes(x=Var2, y=value) )+ geom_boxplot()


colnames(err_matrix_opt)<- c("mod1","mod2","mod3","mod4","mod5")
graph_err <- melt(err_matrix_opt)

ggplot(graph_err,aes(x=Var2, y=value) )+ geom_boxplot()


colnames(fmeasure_matrix_opt)<- c("mod1","mod2","mod3","mod4","mod5")
graph_fmeasure <- melt(fmeasure_matrix_opt)

ggplot(graph_fmeasure,aes(x=Var2, y=value) )+ geom_boxplot()

colnames(gmean_matrix_opt)<- c("mod1","mod2","mod3","mod4","mod5")
graph_gmean <- melt(gmean_matrix_opt)

ggplot(graph_gmean,aes(x=Var2, y=value) )+ geom_boxplot()
```

#Comparison to original model
```{r}

load( file='sensmatrix.RData')


#I can't get this to reimport but I think this is the code to bind cols together
comp_matrix_sens <- cbind(sensitivity_matrix_opt[,4], sensitivity_matrix[,1])

graph_comparison <- melt(comp_matrix_sens)

ggplot(graph_comparison,aes(x=Var2, y=value) )+ geom_boxplot()
```

