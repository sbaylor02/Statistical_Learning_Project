####################
STOP; RUN ALL CODE FROM THROUGH After the EDA Response Variable SECTION PRIOR TO CODING FURTHER!!!!!!!!!!!!!!!!!!!!
#####################


---
title: "Statistical Learning Project"
output: html_notebook
---

Sarah, Pavel, Rose, Catherine, Shravya
East
Statistical Learning Project


```{r}
library(tidyverse)
library(reshape2)
library(readxl)
library(caret)
library(rpart) 
library(partykit) 
library(randomForest)
library(class)
library (rminer)
```

```{r}

#Read in the data
dat <- read_excel("Absenteeism_at_work.xls")

#View the data
glimpse(dat)

```
##Pre-Processing Data
```{r}
#Set factored variables as factors
col <- c("ID", "Reason for absence", "Month of absence", "Day of the week", "Seasons", "Disciplinary failure", "Education", "Social drinker",   "Social smoker", "Pet", "Son")
dat[col] <- lapply(dat[col], as.factor)

#Rename the columns for easier use
colnames(dat) <- c("ID", "Reason", "Month", "Day", "Seasons", "Transportation_expense", "Distance", "Service_time", "Age", "Work_load", "Hit_target", "Disciplinary_failure", "Education", "Children", "Social_drinker", "Social_smoker", "Pet", "Weight", "Height", "BMI", "Absent_time")

#View the data
glimpse(dat)

```


```{r}
# Still need to reset levels on vrariables so ordered factors are graphed in order
```

```{r}
nums <- unlist(lapply(dat, is.numeric))  
dat.num <- dat[ , nums]

```
## EDA Response Variable

### Absent_time
```{r}
summary(dat$Absent_time)

```


```{r}
table(dat$Absent_time)
```

```{r}
#change variable represent missed time one day or greater
dat <- dat %>% mutate(Absent_time= ifelse(dat$Absent_time <=8,0,1))
```

```{r}
dat$Absent_time <- as.factor(dat$Absent_time)
#Transforming to Data Frame
dat <- as.data.frame(dat)
```


```{r}
ggplot(data = dat,
       aes(x = Absent_time)) +
  geom_histogram() + 
  theme_minimal()
```
```{r}
dat %>%
  gather(-Absent_time, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Absent_time)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
```


## EDA Predictors

### ID
### Reason
### Month
### Day

```{r}
dat %>%
  gather(-Day, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Day)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
```


### Seasons

```{r}
#Scatterplots for variable 'Seasons'
dat %>%
  gather(-Seasons, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Seasons)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
```
### Transportation Expense

```{r}
summary(dat$Transportation_expense)
ggplot(data = dat,
       aes(x = Transportation_expense)) +
  geom_histogram(binwidth = 50) + 
  theme_minimal()
```

```{r}
dat %>%
  gather(-Transportation_expense, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Transportation_expense)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
# Possible positive correlation seen between distance and Transportation_expense
```

###Distance
```{r}
summary(dat$Distance)
ggplot(data = dat,
       aes(x = Distance)) +
  geom_histogram(binwidth = 5) + 
  theme_minimal()
```

```{r}
dat %>%
  gather(-Distance, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Distance)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
#Possible Positive correlation seen between distance and Transportation_expense
```

### Service Time
```{r}
ggplot(data = dat,
       aes(x = Service_time)) +
  geom_histogram() +
  theme_minimal()
```

```{r}
dat %>%
  gather(-Service_time, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Service_time)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")

```

### Age

```{r}
ggplot(data = dat,
       aes(x = Age)) +
  geom_histogram() + 
  theme_minimal()
```

```{r}
dat %>%
  gather(-Age, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Age)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")

```
### Workload

```{r}
summary(dat$Work_load)

ggplot(data = dat,
       aes(x = Work_load)) +
  geom_histogram(binwidth = 5000) + 
  theme_minimal()
```

```{r}
dat %>%
  gather(-Work_load, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Work_load)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
```

### Hit Target

```{r}
ggplot(data = dat,
       aes(x = Hit_target)) + 
  geom_histogram() +
  theme_minimal()
```

```{r}
dat %>%
  gather(-Hit_target, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Hit_target)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")

```
### Disciplinary Failure
dat %>%
  gather(-Disciplinary_failure, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Disciplinary_failure)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
  
### Education

dat %>%
  gather(-Education, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Education)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
  
### Children

dat %>%
  gather(-Children, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Children)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
### Social Drinker

dat %>%
  gather(-Social_drinker, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Social_drinker)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
  
###Social Smoker

```{r}
#Scatterplots for variable 'Social_smoker'
dat %>%
  gather(-Social_smoker, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Social_smoker)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
```


### Pet
### Weight

```{r}
dat %>%
  gather(-Weight, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Weight)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
```
### Height

dat.num %>%
  gather(-Height, key = "var_name", value = "value") %>%
  ggplot(aes(x = value, y = Height)) +
  geom_point() +
  facet_wrap(~ var_name, scales = "free")
### BMI


##Additional Preprocessing

```{r}
dat1 <- dat[-1]

####################Someone confirm I did this right. I scaled only numeric not factors. Thats correct right?

#scale
scale <- sapply(dat1, is.numeric)
dat1[scale] <- lapply(dat1[scale],scale)
```


## Initial Method Testing


```{r}

R <- 50 # replications

# create the matrix to store values 1 row per model
err_matrix <- matrix(0, ncol=5, nrow=R)

sensitivity_matrix <- matrix(0, ncol=5, nrow=R)

fmeasure_matrix <- matrix(0, ncol=5, nrow=R)

gmean_matrix <- matrix(0, ncol=5, nrow=R)

# these are optional but I like to see how the model did each run so I can check other output
KNNcm <- matrix(0, ncol=4, nrow=R)
glmcm <- matrix(0, ncol=4, nrow=R)

set.seed(1876)
 

for (r in 1:R){
  
# subsetting data to training and testing data
p <- .6 # proportion of data for training
w <- sample(1:nrow(dat1), nrow(dat)*p, replace=F)
data_train <-dat1[w,] 
data_test <- dat1[-w,]
  
  ########### knn

#Running the classifier

  knn <- knn(data_train[-20],
                       test = data_test[-20],
                       cl=data_train$Absent_time, k=2)
  
#predict doesn't work with KNN for factors
 knntable <- table(knn, data_test$Absent_time)
 
#generate confusion matrix ( the 1 tells the model we care about that output)
 cm_KNN <-  confusionMatrix(data = knntable, reference = data_test[,-20], positive = "1")
 
 KNNcm [[r,1]] <-  cm_KNN$table[1,1]
 KNNcm [[r,2]] <-  cm_KNN$table[1,2]
 KNNcm [[r,3]] <-  cm_KNN$table[2,1]
 KNNcm [[r,4]] <-  cm_KNN$table[2,2]
 
 err_matrix [[r,1]] <-  (cm_KNN$table[1,2]+cm_KNN$table[2,1])/nrow( data_test)
  
  # store the errors (change the 1 to whichever model you have)   
  
 sensitivity_matrix[[r, 1]] <- cm_KNN$byClass[1]
 
 fmeasure_matrix [[r, 1]] <- cm_KNN$byClass[7]
 
 gmean_matrix [[r, 1]] <- sqrt(cm_KNN$byClass[1]* cm_KNN$byClass[2])
  
  ############# Other models go here because they need same training and testing datasets for comparison
  
  ###glm Pavel code:
  model_glm_1 = suppressWarnings(
    train(Absent_time ~ .,
                      data = data_train,
                      method = "glm", 
                      family = 'binomial')
                      )
  
  yhat_glm = predict(model_glm_1, newdata = data_test[,-20])
  
  cm_glm = confusionMatrix(data = yhat_glm, reference = data_test[,20], positive = "1")
  
  glmcm [[r,1]] <-  cm_glm$table[1,1]
  glmcm [[r,2]] <-  cm_glm$table[1,2]
  glmcm [[r,3]] <-  cm_glm$table[2,1]
  glmcm [[r,4]] <-  cm_glm$table[2,2]
  
  err_matrix [[r,2]] <-  (cm_glm$table[1,2]+cm_glm$table[2,1])/nrow( data_test)
  
  # store the errors (change the 1 to whichever model you have)   
  
  sensitivity_matrix[[r, 2]] <- cm_glm$byClass[1]
  
  fmeasure_matrix [[r, 2]] <- cm_glm$byClass[7]
  
  gmean_matrix [[r, 2]] <- sqrt(cm_glm$byClass[1]* cm_glm$byClass[2])
  
#statement indicates where in loop
  cat("Finished Rep",r, "\n")
}

```
Change the matrix names to make easier to interpret

```{r}
#plug in your model in the right place

colnames(err_matrix) <- c("KNN","glm", "other","other", 'other')

colnames(sensitivity_matrix)<- c("KNN","glm", "other","other", 'other')

colnames(fmeasure_matrix) <- c("KNN","glm", "other","other", 'other')

colnames(gmean_matrix) <- c("KNN","glm", "other","other", 'other')

colnames(KNNcm) <- c("True Negative","False Negative", "False Positive","True Positive" )
colnames(glmcm) <- c("True Negative","False Negative", "False Positive","True Positive" )
```

#Logistic regression - Pavel
#I ran 2 models, a regular logistic and a boosted logistic regression. Results below:

#Transforming to Data Frame
```{r}
dat_1 <- as.data.frame(dat)
```

#Transforming variable 'Absent_time' into binomial:
```{r}
dat_1$Absent_time <- ifelse(dat_1$Absent_time <= 8, 'good', 'bad')

#Examining variable 'Absent_time'
table(dat_1$Absent_time)
```

#eliminating columns 1 through 5 since they do not provide any valuable information for prediction, 
#these are just variables that describe the data:
```{r}
dat_1 <- dat_1[,-c(1)]
dat_1$Absent_time <- as.factor(dat_1$Absent_time)
dat_1[1:15] <- scale(dat_1[1:15])

```

```{r}
#Setting number of repetitions
R = 50

# Creating  matrix to store the errors

test_error_A = matrix(0,ncol=1,nrow=R)
test_error_B = matrix(0,ncol=1,nrow=R)
```

```{r}
#A. Running regular logistic regression
set.seed(7359)
for (r in 1:R){
  
  ind = holdout(dat_1$Absent_time,ratio=3/5, mode='stratify') 
  
  tr_xy_A = dat_1[ind$tr,] # train set
  te_XY_A = dat_1[ind$ts,] # test set
  
 # running the actual model
  model_A = train(Absent_time ~ .,
                  data = tr_xy_A,
                  method = "glm", 
                  family = 'binomial') 
  
  yhat_A = predict(model_A, newdata = te_XY_A[,-16])
  
  cm_tr = (confusionMatrix(data = yhat_A, reference = te_XY_A[,16]))
  test_error_A[[r]] = sum(yhat_A!= te_XY_A[,16])/length( te_XY_A[,16])
}
```

```{r}
#B. Boosted logistic regression.
set.seed(7359)
for (r in 1:R){ # replication loop
  
  ind = holdout(dat_1$Absent_time,ratio=3/5, mode='stratify') # stratified train/test split
  
  tr_xy_B = dat_1[ind$tr,] # train set
  te_XY_B = dat_1[ind$ts,] # test set
  
  # running the actual model
  model_B = train(Absent_time ~ .,
                  data = tr_xy_B,
                  method = "LogitBoost")
  
  yhat_B = predict(model_B, newdata = te_XY_B[,-16])
  cm_tr_B = (confusionMatrix(data = yhat_B, reference = te_XY_B[,16]))
  test_error_B[[r]] = sum(yhat_B!= te_XY_B[,16])/length( te_XY_B[,16])  
}
```

#Metrics For regular and boosted logistic regression:
```{r}
#Sensitivity:
Sensitivity_A <- cm_tr$table[1,1]/(cm_tr$table[1,1]+cm_tr$table[2,1])

Sensitivity_B <- cm_tr_B$table[1,1]/(cm_tr_B$table[1,1]+cm_tr_B$table[2,1])

Sensitivity_metric <- as.data.frame(cbind(Sensitivity_A, Sensitivity_B)) %>% 
  `rownames<-`('Sensitivity')

#Renaming the columns:
colnames(Sensitivity_metric)[c(1,2)] <- c("Regular Logistic", "Boosted Logistic")

#Displaying Sensitivity
Sensitivity_metric
```

```{r}
#Computing F1:
#F1 for Regular logistic regression:

cm_tr1 <- as.matrix(cm_tr)
nc <- nrow(cm_tr1) # number of classes
diag <- diag(cm_tr1) # number of correctly classified instances per class 
rowsums <- apply(cm_tr1, 1, sum) # number of instances per class
colsums <- apply(cm_tr1, 2, sum) # number of predictions per class

precision <- diag / colsums 
recall <- diag / rowsums 

#The F-measure gives the harmonic mean of recall and precision 
f1_A <- 2 * precision * recall / (precision + recall) 

#F1 for Boosted Logistic Regression:

cm_tr2 <- as.matrix(cm_tr_B)

nc2 = nrow(cm_tr2) # number of classes
diag2 = diag(cm_tr2) # number of correctly classified instances per class 
rowsums2 = apply(cm_tr2, 1, sum) # number of instances per class
colsums2 = apply(cm_tr2, 2, sum) # number of predictions per class

precision2 = diag2 / colsums2 
recall2 = diag2 / rowsums2 

#The F-measure gives the harmonic mean of recall and precision 
f1_B = 2 * precision2 * recall2 / (precision2 + recall2) 

#Displaying F1 for both models:
data.frame(f1_A, f1_B)

```
```{r}
#Mean of errors:

mean_of_errors <- data.frame(mean(test_error_A), mean(test_error_B))
colnames(mean_of_errors)[c(1,2)] <- c("Regular Logistic", "Boosted Logistic")
mean_of_errors
```

```{r}
#Binding data for the ggplot:
box_matrix <- cbind(test_error_A, test_error_B)
colnames(box_matrix) <- c("test_error_A","test_error_B")
box_matrix <- melt(box_matrix)

#Displaying Box Plot for errors:
ggplot(data = data.frame(box_matrix), aes(x=Var2, y=value)) +
  geom_boxplot() + theme_bw() 
```

<<<<<<< HEAD
#Decision Tree - Sarah

```{r}
#read in the necessary packages
library(rpart)
library(partykit)
```

```{r}
data_train$Absent_time <- as.factor(data_train$Absent_time)
data_test$Absent_time <- as.factor(data_test$Absent_time)
```


```{r}
#write a formula predicting Absent_time from all other variables
form <- as.formula(Absent_time ~ .)
#run a decision tree
tree1 <- rpart(formula = form, data = data_train)
#view the decision tree
tree1

#view a plot of the decision tree
plot(as.party(tree1))
```

```{r}
data_test$tree_pred <- predict(object = tree1, newdata = data_test, type = "class")

data_test$tree_pred

table(data_test$tree_pred, data_test$Absent_time)
```

```{r}
#Set seed to ensure replication
set.seed(1876)
tunegrid <-  expand.grid(.cp = seq(.01:.1, by = .01)) #tune the complexity parameter

R <-  50 #set the number of replications

#create the error matrix to store values
err_matrix <- matrix(0, ncol=5, nrow=R)


for (r in 1:R){
  
  # subsetting data to training and testing data
p <- .6 # proportion of data for training
w <- sample(1:nrow(dat), nrow(dat)*p, replace=F)
data_train <-dat[w,] 
data_test <- dat[-w,]

data_train$Absent_time <- as.factor(data_train$Absent_time)
data_test$Absent_time <- as.factor(data_test$Absent_time)
  
  #tree
  tree_mod = rpart(Absent_time ~ ., data = data_train)
  
  #prediction
  yhat_tree = predict(tree_mod, data_test, type = 'class')
  
  #generate confusion matrix
 cm_tree <-  confusionMatrix(data = table(yhat_tree, data_test$Absent_time), reference = data_test[,-20], positive = "1")
 
 Treecm[[r,1]] <-  cm_tree$table[1,1]
 Treecm[[r,2]] <-  cm_tree$table[1,2]
 Treecm[[r,3]] <-  cm_tree$table[2,1]
 Treecm[[r,4]] <-  cm_tree$table[2,2]
  
  #store the errors
  err_matrix[r, 3] = mean(yhat_tree != data_test$Absent_time)
  
    # store the errors (change the 1 to whichever model you have)   
  
 sensitivity_matrix[[r, 3]] <- cm_tree$byClass[1]
 
 cm_tree$byClass[1]
 
 fmeasure_matrix[[r, 3]] <- cm_tree$byClass[7]
 
 gmean_matrix[[r, 3]] <- sqrt(cm_tree$byClass[1]* cm_tree$byClass[2])
  
  #Just a nice statement to tell you when each loop is done
  # cat("Finished Rep", r, "\n")
  cat("Finished Rep",r, "\n")
}

#view the error matrix for trees
# err_mat_trees

colnames(err_mat_trees) <- 'Trees'
err_mat_trees_melt <-  melt(as.data.frame(err_mat_trees))
colnames(err_mat_trees_melt) <-  c('Method', 'Error')

ggplot(err_mat_trees_melt, mapping = aes(x = Method, y = Error)) +
  geom_boxplot()
```
Change the matrix names to make easier to interpret

```{r}
#plug in your model in the right place

colnames(err_matrix) <- c("KNN","other", "Decision_Tree","other", 'other')

colnames(sensitivity_matrix)<- c("KNN","other", "Decision_Tree","other", 'other')

colnames(fmeasure_matrix) <- c("KNN","other", "Decision_Tree","other", 'other')

colnames(gmean_matrix) <- c("KNN","other", "Decision_Tree","other", 'other')

colnames(Treecm) <- c("True Negative","False Positive", "False Negative","True Positive" )
```


Please make sure you enter code in right format and in line with rest of code.


<<<<<<< HEAD
======

=======
=======
```
>>>>>>> 117449057ef5822b61ea4a1f3a2be5d9a1938d12

#divide data into test and training 
#Transforming to Data Frame

dat_1 <- as.data.frame(dat)
#Transforming variable 'Absent_time' into binomial:

dat_1$Absent_time <- ifelse(dat_1$Absent_time <= 8, 'good', 'bad')

#Examining variable 'Absent_time'
table(dat_1$Absent_time)
#eliminating columns 1 through 5 since they do not provide any valuable information for prediction, #these are just variables that describe the data:

dat_1 <- dat_1[,-c(1:5)]
dat_1$Absent_time <- as.factor(dat_1$Absent_time)
dat_1[1:15] <- scale(dat_1[1:15])


set.seed(1874)
n <- nrow(dat_1)
#create an integer sample of the number of rows in the data set.
#We want 20% in the test data set so
# .2 time the numer of rows (n) gives the sample size.
# test_idx will have 20% of the row numbers in it
test_idx <- sample.int(n,size= round(0.2 * n))
#Use test_idx to subset NHANES for the test data
test <- dat_1[test_idx,]
#Use the inverse of test_idx, NOT test.idx to subset NHANES for the train data set
train <- dat_1[-test_idx,]

#Set the seed to ensure similar "random" selections as the other processes
set.seed(1874)
library(randomForest)
nam <- names(dat_1[1:15])
formfull <- as.formula(paste("Absent_time ~" , paste(nam,collapse =" + ") ) )
#Use the randomForest on the training data with 6 variables tried at each split and 100
#trees created
diag_forest <- randomForest(formfull,
                            data=train,
                            mtry=6,
                            ntree=501,
                            na.action=na.roughfix)
diag_forest
#Give the importance chart to determine which variables were most often used over the
#course of the bootstrapped forest
importance(diag_forest)

#Use the random forest to make predictions on the classification of the test data
test_forest <- predict(diag_forest,newdata = test,type="class")
#Confusion Matrix for the Random Forest with all of the variables
cm_tr<- table(test_forest,test$Absent_time)



#Computing F1:

cm_tr1 <- as.matrix(cm_tr)
cm_tr1
nc = nrow(cm_tr1) # number of classes
diag = diag(cm_tr1) # number of correctly classified instances per class 
rowsums = apply(cm_tr1, 1, sum) # number of instances per class
colsums = apply(cm_tr1, 2, sum) # number of predictions per class

precision = diag / colsums 
recall = diag / rowsums

#The F-measure gives the harmonic mean of recall and precision 
f1_rf = 2 * precision * recall / (precision + recall) 

data.frame(precision, recall, f1_rf) 


#Sensitivity:
Sensitivity_RF <- cm_tr[1,1]/(cm_tr[1,1]+cm_tr[2,1])
Sensitivity_metric <- as.data.frame(cbind(Sensitivity_RF)) %>% 
  `rownames<-`('Sensitivity')


#Renaming the columns:
colnames(Sensitivity_metric)[c(1)] <- c("Random Forest")

#Displaying Sensitivity
Sensitivity_metric



#calculating error
test_error_RF<- diag_forest$err.rate

mean_of_errors_RF <- data.frame(mean(test_error_RF))
colnames(mean_of_errors_RF)[c(1)] <- c("Random Forest")
mean_of_errors_RF

test_error_RF2 <- data.frame(test_error_RF)
test_error_RF2
#Displaying Box Plot for errors:
ggplot(test_error_RF2, aes(y=OOB)) + geom_boxplot() + labs(x= 'Random Forest', y= 'Out of Bag Error', title= 'Out of Bag Error for Random Forest')

```
>>>>>>> add75b1ee1544e6545b864f94f4d1210f7c60889
